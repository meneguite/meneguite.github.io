{"pages":[{"title":"Sobre","text":"Mais sobre mim","link":"/about/index.html"}],"posts":[{"title":"OAuth","text":"O OAuth é um padrão aberto para autorização, responsável por fornecer um método para acessar os recursos do servidor em nome de seu proprietário, além de fornecer também um processo para que os usuários possam autorizar o acesso de terceiros aos seus recursos, sem compartilhar suas credenciais. O OAuth permite a aplicações acessar dados de um usuário de forma segura, sem que para isso o usuário necessite disponibilizar suas senhas. HistóriaO OAuth teve seu início por volta de novembro de 2006, quando Blaine Cook foi trabalhar na implementação Twitter OpenID e ao buscar uma maneira de usar o OpenID em conjunto com a API do Twitter se juntou a outros que possuíam necessidades similares, como Chris Messina, David Recordon e Larry Halff, analisaram as funcionalidades do OpenID e soluções práticas de outras empresas, e chegaram a conclusão de que não havia nenhum padrão aberto para a delegação de acesso à API. Em julho de 2007, agora com o apoio do Google, foi elaborada uma especificação inicial e o projeto foi aberto a qualquer pessoa interessada em contribuir. Em 3 de Outubro de 2007, a versão final do Núcleo OAuth 1.0 foi lançada. A primeira versão do OAuth foi projetada para lidar com autorização de aplicações web cliente-servidor, não definindo como lidar com autorização em aplicações móveis, desktop, javascript ou extensões do navegador por exemplo. Assim essas aplicações ao implementar o OAuth 1.0, normalmente possuíam métodos inconsistentes e muitas vezes de qualidade inferior, visto que eram obrigados a adaptar o protocolo a sua necessidade. Com o lançamento da versão 2.0 do protocolo, essa limitação foi eliminada, visto que já foi projetada para trabalhar com todos esses tipos de aplicações de forma nativa. Porque usar uma OAuth ao invés de senhas?Para Boyd(2012) existem várias razões para se utilizar OAuth, sendo as principais: Confiança: O usuário pode não confiar em fornecer a senha a sua aplicação. Acesso e risco além do necessário: Ao fornecer sua senha a uma aplicação, o usuário disponibiliza não somente os dados necessários para ela, mais sim todos os dados que estão vinculados a aquela conta. Assim quando o usuário confia sua senha, cabe à mesma armazená-las de forma segura, criando mecanismos com o objetivo de evitar o vazamento dessa informação, o que pode gerar um custo desnecessário para a empresa. Alteração de Senha: Ao alterar a senha de uma conta, todas as aplicações vinculadas a ela irão parar de funcionar, fazendo que o usuário tenha que acessar aplicação a aplicação para inserir a nova senha. Revogação: A única maneira de revogar o acesso à aplicação será o usuário alterar suas senhas, o que também revoga o acesso a todos os outros aplicativos que o mesmo tenha concedido essa informação. Papéis no OAuthExistem vários componentes chaves que compõe os fluxos do protocolo OAuth. São eles: Servidor de recursos : O servidor que hospeda os recursos de propriedade do usuário que estão protegidos por OAuth. Este é normalmente um provedor de API que mantém e protege os dados, como fotos, vídeos, calendários e contatos. Proprietário dos recursos: Normalmente, o usuário de um aplicativo, o proprietário do recurso tem a capacidade de conceder acesso aos seus próprios dados hospedado no servidor de recursos. Cliente: É aquele que envia uma requisição à API, solicitando um recurso protegido em nome do proprietário. Servidor de autorização: O servidor responsável por receber a autorização de proprietário do recurso e conceder tokens de acesso para o cliente poder acessar, em nome do proprietário, os recursos protegidos hospedados em um servidor de recursos. Fornecedores de API menores podem usar o mesmo aplicativo e URL, tanto para o servidor de autorização, quanto para o servidor de recursos. Perfis de Clientes no OAuth 2.0Existem três perfis de clientes implementados no OAuth 2.0, são eles: Aplicação executada pelo servidor (server-side), Aplicação executada pelo navegador de internet do cliente (client-side) e Aplicações nativas Aplicação executada pelo servidor (server-side)Para esse perfil a aplicação web é acessada por um usuário, proprietário do recurso, e ao ser consultada faz as chamadas da API apropriadas usando uma linguagem de programação do lado do servidor, não disponibilizando ao usuário o acesso aos tokens OAuth emitidos pelo servidor de autorização . Na ilustração abaixo é demonstrado o fluxo de uma aplicação que busca autorização pelo lado do servidor. Aplicação executada pelo servidor (server-side) Aplicação executada pelo navegador do cliente (client-side)Nesse perfil o acesso a API é efetuada diretamente no cliente, por intermédio de seu navegador, onde o mesmo tem acesso ao código do aplicativo e suas solicitações. Dessa forma o aplicativo pode ser distribuído em linguagem javascript, ou em uma extensão do navegador ou ainda usando uma tecnologia plug-in como o Flash. Esse perfil, por rodar em um ambiente com pouco ou nenhum controle, possui fragilidades as quais fazem com que, por medida de segurança, alguns provedores não permitam o armazenamento de credenciais para clientes que utilizam esse perfil. Aplicação executada pelo cliente (client-side) Aplicações nativasAplicações com esse perfil são desenvolvidas para rodar como um aplicativo nativo em diversos dispositivos como computadores, smartphones ou tablets. Podendo assim aproveitar de todos os recursos do sistema operacional ao qual o dispositivo disponibiliza. Essas aplicações possuem características muito similares às executadas pelos navegadores de internet, como por exemplo, o fato de não ser um ambiente confiável para o armazenamento de credenciais. Porém como destaca Boyd(2012), uma vez que o aplicativo é instalado, pode não ter acesso a todos os recursos, como teria em um navegador de internet. Fluxo de AutorizaçãoCada um dos perfis citados anteriormente precisa fazer uso de um protocolo adequado para a obtenção de autorização do proprietário do recurso de acesso a seus dados. Em seu núcleo, o protocolo OAuth 2.0 define quatro principais mecanismos para a obtenção dessa autorização, além de também definir um de extensão para permitir tipos de autorização adicionais . Concessão de código de autorizaçãoEsse tipo de concessão é mais adequado para aplicações web que utilizam o perfil server-side. Depois que o proprietário do recurso autorizou o acesso a seus dados, eles são redirecionados de volta para a aplicação web com um código de autorização como um parâmetro de consulta na URL, sendo que este código deve ser trocado por um token de acesso pelo aplicativo cliente. Esta troca é feita de servidor para servidor e requer o client_id e client_secret, impedindo até mesmo o proprietário do recurso de obter o token de acesso. Este tipo de concessão também permite o acesso de longa duração para uma API usando fichas de atualização. Uma representação desse fluxo é demonstrada na ilustração abaixo, onde podemos visualizar a solicitação do recurso pelo cliente para o proprietário do recurso, que responde com uma concessão de autorização gerada pelo servidor de autorização, logo após a concessão de autorização é enviada ao servidor de autorização, que responde com um token de acesso que é usado para acessar o servidor de recursos e obter os dados aos quais obteve autorização prévia. Fluxo de Código de Autorização Concessão implícitaAs concessões implícitas estão disponíveis como um método simplificado de geração do token de acesso para clientes públicos baseados em navegadores, pois ao invés de gerar uma concessão intermediária, como acontece no fluxo de Código de autorização, o token de acesso é emitido diretamente ao cliente depois de autenticar o proprietário do recurso. As etapas ilustradas na imagem abaixo demonstram o fluxo de uma concessão implícita, onde : 1ª Etapa: O aplicativo solicita ao usuário a permissão de acesso a API do Facebook. 2ª Etapa: O usuário se conecta ao servidor de recursos por meio de uma URL que inclui informações sobre o aplicativo que está tentando acessar a API, como por exemplo, o client_id, e fornece um nome de usuário e senha para fazer login no facebook. 3ª Etapa: Com login efetuado com sucesso, o facebook concede ao aplicativo um token de acesso. 4ª Etapa: O aplicativo pode obter acesso aos recursos do usuário ao se utilizar do token recebido na etapa anterior. Fluxo de concessão implícita Fonte: KULP (2013) Concessão com usuário e senhaEste tipo de concessão consiste em ao obter um nome de usuário do proprietário de um recurso e uma senha para que esses dados possam ser trocados por um token de acesso OAuth. Este tipo de concessão deve ser usado somente para clientes altamente confiáveis, tais como aplicações móveis escritas pelo provedor da API, visto que a senha do usuário é exposta ao cliente, que não necessita de armazená-la no dispositivo. Após a autenticação inicial, apenas o token OAuth precisa de ser armazenado. Como a senha não é armazenada, o usuário pode revogar o acesso ao aplicativo sem alterar a senha, e o token é limitado a um conjunto de dados previamente autorizado pelo proprietário dos recursos, de modo que este tipo de concessão ainda proporciona maior segurança sobre a autenticação de usuário / senha tradicional. Concessão de credenciais para o clienteA concessão de credenciais de um cliente permite que um aplicativo possa obter um token de acesso a recurso de propriedade do cliente quando a autorização foi previamente definida com o servidor de autorização. Sendo esse tipo de concessão adequada para aplicações que precisam acessar APIs, tais como serviços de armazenamento ou banco de dados em nome da aplicação ou do fornecedor da aplicação e não em nome de um usuário específico. Concessão de credenciais para um dispositivoO concessão de credenciais para um dispositivo foi criada para permitir que o protocolo OAuth possa ser usado em dispositivos mais limitados, sem os recursos necessários para obter uma autorização por si só. Essa consiste em iniciar o fluxo no dispositivo e então utilizar dispositivo auxiliar, como um computador, por exemplo, para acessar um site e aprovar o acesso, digitando um código de autorização exibida no dispositivo. BibliografiaBOYD, R. Getting Started with OAuth 2.0. Sebastopol: O’Reilly Media, 2012. KULP, T. Access Online Services with the Windows Runtime and OAuth. MSDN Magazine, 2014. Disponivel em:. Acesso em: Março 2014.","link":"/2014/04/14/oauth/"},{"title":"Replicação com OpenLdap","text":"Nesse artigo iremos demonstrar o funcionamento do sistema de replicação com o OpenLDAP. Replicação é a manutenção de uma cópia, seja parcial ou total, dos dados em outros servidores. Este é um método muito utilizado quando trabalhamos em um ambiente corporativo, onde temos a necessidade de alta disponibilidade nos serviços. Base Teórica Sobre Replicação no OpenLdapReplicação é a manutenção de uma cópia, seja parcial ou total, dos dados em outros servidores. Esse é um método muito utilizado quando trabalhamos em um ambiente corporativo, onde temos a necessidade de alta disponibilidade nos serviços. No OpenLDAP existem duas técnicas distintas de replicação as quais são o slurpd e o syncrepl, sendo que a slurpd é uma técnica mais antiga a qual foi descontinuada na versão 2.4 do OpenLDAP por possuir uma série de limitações que foram supridas por sua sucessora a syncrepl. As principais limitações eram a replicação parcial de uma base e a utilização de mais de um servidor master. Quando trabalhamos com o syncrepl, o servidor LDAP pode assumir duas posturas quanto à replicação: master ou slave. Quando master, o servidor assume todas as funções de um servidor OpenLDAP, desde a inserção, atualização e consulta dos dados. Porém, quando slave, o servidor só aceitará execuções de consultas em sua base de dados quando originadas de máquinas clientes. Assim, para que qualquer informação seja alterada, a solicitação deverá ser feita ao servidor Master, o qual se encarregará de replicar as alterações para seus servidores slaves. Replicação Master x SlaveNesse método de replicação temos um único servidor master, o qual tem seu conteúdo replicado em todos os seus servidores slaves. Nesses servidores slaves não ocorre entrada de dados, apenas replicam passivamente os dados de um servidor principal. Esse método de replicação é o mais comum e atende a grande parte das demandas de servidores LDAP. Replicação Master x Master (Multimaster)Replicação multimaster é o método de replicação mais recente no OpenLDAP, porém já implementado no Active Directory desde suas primeiras versões. Esta é uma replicação que atende a demandas muito singulares e apesar de funcionar muito bem, ainda é pouco difundida e aplicada. Esta replicação consiste na utilização de dois ou mais servidores masters, independentes, os quais possuem todas as suas funcionalidades ativadas, porém é criado por parte dos servidores um controle interno para que seja possível manter a integridade dos dados, algo que era muito mais simples de controlar quando existia uma única entrada de dados. Diretórios DistribuídosUtilizando o OpenLDAP com o método de replicação syncrepl podemos não somente criar uma cópia da árvore de diretórios em outros servidores, mas também criar políticas de replicação e replicar a cada servidor somente aquilo que se pretende que o mesmo tenha acesso, assim por exemplo, quando temos uma empresa com sede em Minas Gerais e filial em São Paulo, a mesma não precisa replicar toda sua base para a filial, apenas aqueles usuários que a pertençam, evitando assim um tráfego desnecessário na rede além de aumentar a segurança. Exemplo de ConfiguraçãoBom, abaixo iremos apresentar um exemplo de configuração de replicação para o OpenLDAP fazendo uso da estrutura Master x Slave. Consideraremos que já possuímos dois servidores configurados com o servidor OpenLDAP instalado e funcionando, assim apenas demonstraremos os parâmetros relacionados as replicações entre os servidores. A distribuição Linux utilizada foi Debian 5 e o OpenLDAP na versão 2.4.9. Configuração Master X SlaveConfigurando o Servidor MasterInicialmente o arquivo a ser alterado é o arquivo principal de configuração do OpenLDAP o /etc/ldap/slapd.conf. Alterando o parâmetro modulepath para syncprov e inserindo as seguintes linhas logo abaixo da opção “index”: 123overlay syncprovsyncprov-checkpoint 100 10syncprov-sessionlog 100 Devemos Inserir também junto a ACL responsável pelos atributos de senha, userPassword e shadowLastChange a seguinte linha: 1by dn=\"cn=replicator,dc=dominio,dc=com,dc=br\" read Assim inserimos a permissão para o usuário replicador, ao qual deve ser criado anteriormente para ler os campos de senha dos usuários, pois sem o acesso a leitura ele não conseguiria efetuar a replicação completa da base. Neste ponto foi reiniciado o servidor com o comando: 1/etc/init.d/slapd restart Configurando o Servidor SlaveIniciaremos a configuração do servidor slave editando o arquivo de configuração /etc/ldap/slapd.conf e removendo o caractere “#” antes da linha “rootdn”, e logo após inserimos as seguintes linhas abaixo de “index”: 12345678910111213syncrepl rid=1provider=ldap:// servidor1.dominio.com.br:389type=refreshAndPersistretry=\"5 + 5 +\"interval=00:00:00:10searchbase=\"dc=dominio,dc=com,dc=br\"filter=\"(objectClass=*)\"scope=subattrs=\"*\"schemachecking=on 41bindmethod=simplebinddn=\"cn=replicator,dc=dominio,dc=com,dc=br\"credentials=senha_do_usuario_replicator Após os procedimentos acima citados, paramos o servidor OpenLDAP, removemos os diretórios e novamente iniciamos o servidor. Para isso utilizamos as seguintes linhas de comando: 123/etc/init.d/slapd stoprm /var/lib/ldap/*/etc/init.d/slapd start Assim temos agora os dois servidores configurados, sendo que os dados do servidor1.dominio.com.br estão sendo replicados para o servidor2.dominio.com.br, porém o mesmo não tem autoridade sobre os dados fazendo com que para alterarmos qualquer informação na base, teremos que fazer isso no servidor1.dominio.com.br e essa atualização será replicada de imediato para o servidor slave.","link":"/2010/03/04/replicacao-com-openldap/"},{"title":"GoLang, desbravando uma linguagem de programação - Parte 1","text":"Image from: http://kirael-art.deviantart.com/art/Go-lang-Mascot-458285682 Já faz muito tempo que não escrevo um artigo, mas já fazia algum tempo que queria voltar a escreve-los. Hoje resolvi aprender uma nova linguagem de programação e também documentar esse processo na esperança de talvez poder ajudar alguém, não só aprender a própria linguagem Go, como qualquer outra linguagem de programação. Esta série de artigos não tem a pretensão de ser um guia definitivo, ou um super manual da linguagem, mas sim descrever como eu aprendo uma nova linguagem, pontos importantes e minhas impressões da mesma. Bom então vamos lá… O que é GoGo é um projeto de código aberto, multiplataforma, desenvolvido e mantido pelo time do Google além de outros contribuidores e distribuído com a licença BSD. O projeto nasce com o objetivo de tornar seus programadores mais produtivos e ser uma linguagem expressiva, concisa, limpa e eficiente. Bom, isso é o que está descrito em sua documentação, por hora vamos apenas acreditar :) . Podemos encontrar mais informações sobre o projeto aqui. Leia a documentação da linguagem, esse é o primeiro passo para entender o que é e o que esperar ao aprendê-la. Saber os objetivos do ecossistema é fundamental para entender onde é possível e viável usar a linguagem. Perceba que entender isso é como conhecer qualquer ferramenta que se proponha a usar, tentar apertar um parafuso com um martelo tende a não dar muito certo 😁. E porque os objetivos do ecossistema e não da linguagem? Bom, esse é um erro muito comum para iniciantes. É fundamental perceber que o que limita o uso de uma linguagem, não é sua sintaxe. No geral a linguagem e seu ecossistema nascem e evoluem em um mesmo objetivo, porém é possível que isso mude com o tempo. O JavaScript é um exemplo muito claro disso, foi por muito tempo uma linguagem limitada ao browser, com aplicabilidade apenas em sistemas web, porém esse cenário mudou completamente após a chegada do NodeJs, hoje vemos JavaScript para todos os lados, seja em servidores ou até em pequenos dispositivos embarcados. Uma impressão inicial, e que me agrada bastante, é que logo no inicio de sua documentação, Go deixa claro ter seu foco em aproveitar o máximo de maquinas multicore e em rede, esse objetivo é super importante, porque iniciar em um ecossistema que não trabalha bem com escalabilidade seja ela vertical ou horizontal é hoje na minha visão uma perda de tempo na grande maiorias dos casos. Outro ponto que me interessou bastante é o fato de Go ser é uma linguagem com tipagem estática e compilada, o que destoa bastante das linguagens que venho trabalhando nos últimos tempos, e pode ser um trufo interessante em novos projetos. Entendendo a sintaxe básica da linguagemAo iniciar em uma linguagem é importante entender sua sintaxe básica e sempre que possível suas origens. Quase todas as linguagens modernas não começaram do zero, foram inspiradas em linguagens já existentes. Traçar sua ancestralidade ajuda a criar familiaridade mais rapidamente caso já possua domínio de outra com ancestral comum. Por exemplo, linguagens baseadas em C tendem a ter características em comum e quanto antes perceber isso, mais rápido vai se sentir a vontade na nova linguagem. Go é um exemplo disso, muito de sua sintaxe é semelhante ao C, com pequenas mudanças como a falta de parênteses em volta de estruturas como for e if por exemplo. É super tranquilo se adaptar as mudanças.. abaixo um exemplo de código Go. 1234567package mainimport \"fmt\"func main() { fmt.Println(\"Hello World\")} Todos os detalhes da Especificação da linguagem podem ser encontrados aqui, é sempre bom dar uma olhada, mas essa documentação pode e deve ser consultada sempre que alguma dúvida aparecer. A documentação da especificação do Go é muito detalhada e bem escrita, eu realmente me senti confortável ao fazer uma leitura rápida da mesma. Configurando o ambiente de desenvolvimentoPara iniciarmos em uma nova linguagem, quase sempre, precisamos de um ambiente bem configurado de forma possibilitar a fluides no aprendizado. Hoje dificilmente instalo qualquer ambiente diretamente em minha maquina, por algum tempo usei o Vagrant para isso, porém hoje tenho trabalho quase exclusivamente com o Docker, ele possibilita testar e descartar sempre que não uso mais qualquer ambiente, deixando minha máquina sempre livre. Outro ponto importante é que consigo reproduzir o exato ambiente ao qual o sistema vai rodar quando em produção, evitando problemas de compatibilidade no momento em que coloco o sistema no ar. O intuito desse artigo não está em usar o Docker, assim apenas me limitarei a mostrar os passos feitos e não a explica-los a fundo, mas sugiro fortemente que tire um tempinho para dominar ele, provavelmente vai ser um divisor de água no seu dia a dia como desenvolvedor. Para iniciarmos o projeto criei um arquivo chamado “docker-compose.yml” na raiz do projeto com o seguinte conteúdo: 1234567version: \"2\"services: app: image: golang:1.9-stretch volumes: - ./:/go/src/learning-go-lang working_dir: /go/src/learning-go-lang Esse arquivo é responsável por inicializar com as configurações adequadas o contêiner docker para a aplicação. Posteriormente criei um arquivo de nome de “main.go” ainda na raiz do projeto com o seguinte conteúdo: 1234567package mainimport \"fmt\"func main() { fmt.Println(\"Hello World\")} Tudo finalizado e configurado, basta executar o comando “docker-compose run app go run main.go”, esse comando ao ser rodado a primeira vez baixa o container configurado no arquivo “docker-compose.yml” e posteriormente executa o arquivo main.go. (Esse processo pode demorar um pouco a primeira vez, dependendo de sua conexão com a internet, porém nas demais o processo é super rápido). Assim, após finalizado o processo, todo o ambiente configurado e pronto para começarmos os trabalhos devera gerar o tão esperado Hello World em sua última linha. Próximos CapítulosPara continuação dessa série alguns dos próximos passos serão, entender melhor como funciona o sistema de Gerenciamento de Dependências do Go, todos os projetos, quase sem exceção dependem de ferramentas externas, Go parece ser bem completo, mas ter e entender como funciona seu gestor de dependência é fundamental. O passo seguinte será identificar se existem e quanto maduro são os frameworks disponíveis para a linguagem, por fim minha ideia é criar uma API simples usando os principais conceitos da linguagem e posteriormente a levar para produção para que seja possível perceber as dificuldades envolvidas no processo. Bom por hoje é isso, em breve seguimos.. Click aqui para acessar a segunda parte do artigo!! Ou Click aqui para acessar a terceira e ultima parte do artigo!!","link":"/2017/10/01/golang-desbravando-uma-linguagem-de-programacao-parte-1/"},{"title":"GoLang, desbravando uma linguagem de programação - Parte 2","text":"Este artigo é a segunda parte de uma sequência de artigos sobre meu processo de aprendizado de uma nova linguagem de programação, nessa série tenho o objetivo de documentar esse processo na esperança de talvez poder ajudar alguém, não só aprender a própria linguagem Go, como qualquer outra linguagem de programação. A parte 1 dessa série pode ser lida aqui. Antes de começarmosUm ponto que venho percebendo durante meus estudos em Go, é que é muito fácil perceber o porque quase sempre se usa o termo Golang e não somente Go como inicialmente concebido. É inviável achar qualquer coisa em um buscador usando apenas Go, assim provavelmente irei me referir algumas vezes ao Go usando este termo e acabei por alterar os títulos dos artigos para facilitar a indexação nos mecanismos de busca. Outro adendo importante que gostaria colocar é um utilitário web disponibilizado pela própria Google para testarmos a linguagem, sendo possível testar a Golang mesmo sem ter nada instalado localmente. Esse utilitário denominado The Go Playground pode ser encontrado em https://play.golang.org e realmente ajuda muito nos testes iniciais da linguagem. https://play.golang.org Mas afinal quem usa Go?Bom, além do próprio Google, outras grandes empresas estão investindo no Go, com a Sendgrid, Globo.com, Mercado Livre, Magazine Luiza, Walmart além de várias outras gigantes no mercado. Um caso de uso bem interessante é o da sendgrid que pode ser lindo aqui onde seu Co-founder Tim Jenkins descreve os motivos da escolha da linguagem e o mais importante, os problemas encontrados nessa adoção e como eles superaram eles. Outro caso de uso interessante é o do Globo.com que pode ser visto aqui, onde o analista Vinicius Pacheco descreve como saíram de 200 para 19 mil cadastros por segundo usando microservices e Go. Quando usar o Go ?Sinto muito, mas Golang não é a bala de prata que estava esperando 😞, pode parecer uma brincadeira, mas ainda hoje, mesmo com tantos artigos publicados sobre o assunto, não falta desenvolvedores em busca de uma linguagem/ecossistema que atenda todas as demandas possíveis da melhor forma. Para esses, eu tenho uma triste notícia, isso provavelmente nunca vai acontecer. Entender o que cada ecossistema de linguagem tem de melhor, e onde é interessante ou não usá-la é fundamental para que possamos prover sempre a melhor solução para cada problema. Go tem objetivos muito claros, se precisa de um sistema multiplataforma, altamente escalável, com desempenho similar outras linguagens compiladas como C, que trabalhem com programação concorrente de forma nativa e de maneira altamente otimizada, então meu amigo, Go é pra você 😉. Se esses objetivos não se alinham com seu projeto, então esqueça, provavelmente Go não é a melhor opção. Para se manter fiel a seus objetivos, Golang tende a ser simplista ao extremo, e não implementa, ou implementa de forma alternativa vários mecanismos hoje comum em quase todas as linguagens de alto nível. Para citar alguns desses pontos: Não tem classes; Não tem herança; Não é possível fazer overload de métodos; Não existe sistemas de Exceptions (try/catch); 😱 Não tem conversões numéricas implícitas; Não possui Operadores Ternários; 😢 Isso mesmo, pode parecer estranho, eu mesmo ainda não me acostumei com isso, mas Go tem um suporte a orientação a objetos extremamente peculiar. Mas não desista ainda, por exemplo, para suprir a necessidade criada pela falta de classes, Go disponibiliza as Structs, que irão permitir trabalhar de forma similar a que estamos acostumados com as classes. Iremos ver isso com mais calma em um próximo artigo. O tratamento de erros em Go vem se destacando em meus estudos como um grande ponto fraco do ecossistema, e é comum ver que a maioria dos desenvolvedores usam a capacidade de Golang de retornar vários valores em uma mesma função para fazer um tratamento que pra mim ainda parece um pouco primitivo. Abaixo um exemplo de tratamento de erro: 12345f, err := os.Open(\"filename.ext\")if err != nil { log.Fatal(err)} Para Go os erros não podem ser delegados, são considerados com parte fundamental do código. Um texto interessante que fala sobre isso, escrito por Elton Minetto pode ser lido aqui. Gerenciamento de dependênciasNos dias de hoje dificilmente conseguiremos trabalhar em um sistema completamente sem dependências externas, até por que não faria sentido reinventar a roda a cada novo projeto. Go vem inserido em um ecossistema muito rico de funcionalidades, traz já em sua base, funcionalidades como testes por exemplo, que na maioria das linguagens ficam a cargo de pacotes de terceiros. Porém isso não acontece com o sistema de gerência de dependências, o que é uma pena, considerando o grau de importância de um sistema realmente confiável para esse fim. Não tendo uma ferramenta padrão para isso, acabou por ficar por conta da comunidade o desenvolvimento de uma ferramenta para esse fim, e assim fizeram, várias opções foram surgindo, cada uma com sua abordagem e incompatíveis entre-se, dessas aparentemente a mais relevante é a Glide, que parece ser entre todas a mais madura e concisa. Porém esse problema parece estar chegando ao fim, enquanto escrevo esse artigo existe uma iniciativa da própria comunidade em criar uma ferramenta de nome dep que ainda é um experimento oficial, mas tende a se tornar a ferramenta oficial para esse fim. Nessa série já vamos iniciar com ele, visto que já é considerado “safe for production use” apesar de estar em processo acelerado de desenvolvimento. O processo de instalação do dep é extremamente simples, mas varia de acordo com seu ambiente. Para essa série, irei continuar usando o docker, mas a imagem padrão não mais vai nos atender, assim vamos fazer uma build customizada já com o dep disponível. Para isso, vamos criar um novo arquivo config/docker/go/Dockerfile, que conterá a receita para criar a imagem do docker. 1234# Arquivo config/docker/go/DockerfileFROM golang:1.9-stretchENV TZ America/Sao_PauloRUN go get -u github.com/golang/dep/cmd/dep E posteriormente vamos precisar alterar nosso arquivo “docker-compose.yml” para que ele use essa imagem, ficando assim: 12345678version: \"2\"services: app: build: ./config/docker/go volumes: - ./:/go/src/learning-go-lang working_dir: /go/src/learning-go-lang Para executar o build executamos o comando “docker-compose build” e tudo correndo bem podemos voltar a executar o comando “docker-compose run app go run main.go” e teremos novamente impresso nosso querido Hello World. Próximos CapítulosO passo seguinte será identificar se existem e quanto maduro são os frameworks disponíveis para a linguagem, por fim minha ideia é criar uma API simples usando os principais conceitos da linguagem e posteriormente a levar para produção para que seja possível perceber as dificuldades envolvidas no processo. Obs.: Os códigos produzidos durante o projeto podem ser acompanhados usando o repositório hospedado no github -> https://github.com/meneguite/golang-learning Bom por hoje é isso, em breve seguimos.. Click aqui para acessar a terceira e ultima parte do artigo!!","link":"/2017/10/08/golang-desbravando-uma-linguagem-de-programacao-parte-2/"},{"title":"Adapter Pattern - Design Patterns com Typescript","text":"Nesse artigo pretendo apresentar de uma forma simplificada o conceito de Adapter Pattern, que é um padrão de projeto extremamente útil no dia a dia para qualquer desenvolvedor. Sua função é converter uma interface de uma classe para outra esperada pelo cliente, possibilitando que classes com interfaces incompatíveis trabalhem juntas. Para simplificar o conceito, imagine que tenha um novo notebook que comprou fora do brasil, seu plugue de energia vem no padrão europeu, infelizmente incompatível com as tomadas brasileiras, para resolver esse problema é simples, vai precisar de um adaptador. Bom, o Adapter Pattern tem exatamente a mesma função, conectar dois pontos incompatíveis entre si. Com o conceito entendido, hora de colocar isso no código em um exemplo mais real encontrado no dia a dia de muitos desenvolvedores, de forma muito simplificada é claro, mas que já vai nos dar uma boa ideia de como expandirmos e aplicarmos isso no nosso dia a dia. Considere que tem hoje um sistema de log que salva em um arquivo local todas as informações geradas pela aplicação, e que esse possui a seguinte interface e implementação: 12345678910interface Logger { info(message: string): Promise;}class FileLogger implements Logger { public async info(message: string): Promise { console.info(message); console.info('This Message was saved with FileLogger'); }} Essa mesma implementação é usada por todo o sistema e sempre gerado um log o mesmo é tratado por essa classe FileLogger como no exemplo abaixo: 12345678910111213141516171819class NotificationService { protected logger: Logger; constructor (logger: Logger) { this.logger = logger; } public async send(message: string): Promise { //... Implementation await this.logger.info(`Notification sended: ${message}`); }}// Inicialização com o FileLogger(async () => { const fileLogger = new FileLogger(); const notificationService = new NotificationService(fileLogger); await notificationService.send('My notification');})(); Ao rodar esse código é esperado algo como: 123# tsc && node adapter/index.jsNotification sended: FoiiThis Message was saved with FileLogger Porém agora precisamos usar uma nova forma de salvar os logs, pois com o crescimento de nossa aplicação, salvar em disco não é mais uma alternativa, assim precisamos usar uma implementação que responde pela seguinte interface e implementação: 12345678910interface CloudLogger { sendToServer(message: string, type: string): Promise;}class AwsLogger implements CloudLogger { public async sendToServer(message: string, type: string): Promise { console.info(message); console.info('This Message was saved with AwsLogger'); }} Ou seja, para que possamos usar essa nova classe precisaríamos refatorar todo nosso código para usar o novo formato de envio de log, ou usar um adapter, o que convenhamos, parece uma opção bem melhor 🙂.Esse adapter poderia ser algo como: 1234567891011class CloudLoggerAdapter implements Logger { protected cloudLogger: CloudLogger; constructor (cloudLogger: CloudLogger) { this.cloudLogger = cloudLogger; } public async info(message: string): Promise { await this.cloudLogger.sendToServer(message, 'info'); }} Com esse adapter poderíamos enviar uma instância do mesmo e manter todo o código de nossas implementações intacto, apenas alterando a inicialização como pode ser visto no exemplo abaixo: 1234567// Inicialização com o AwsLogger(async () => { const awsLogger = new AwsLogger(); const cloudLoggerAdapter = new CloudLoggerAdapter(awsLogger); const notificationService = new NotificationService(cloudLoggerAdapter); await notificationService.send('My notification');})(); Assim teríamos uma saída esperada: 123# tsc && node adapter/index.jsNotification sended: FoiiThis Message was saved with AwsLogger Como podem perceber esse é um padrão extremamente útil e é fundamental para qualquer desenvolvedor o entendimento desse padrão. Bom por hoje é isso, mais em breve pretendo escrever outros artigos como esse, com intuito de simplificar e trazer para o nosso dia a dia os padrões de projetos ou design patterns mais comuns aplicados usando o typescript. O Código completo para esse implementação pode ser encontrado em: https://github.com/meneguite/typescript-design-patterns/blob/master/adapter/index.ts Outros padrões de Projetos: Adapter Pattern Observer Pattern","link":"/2019/06/20/design-patterns-com-typescript-adapter/"},{"title":"GoLang, desbravando uma linguagem de programação - Parte 3 (Final)","text":"Este artigo é a terceira e ultima parte de uma sequência de artigos sobre meu processo de aprendizado de uma nova linguagem de programação, nessa série tenho o objetivo de documentar esse processo na esperança de talvez poder ajudar alguém, não só aprender a própria linguagem Go, como qualquer outra linguagem de programação. A parte 1 dessa série pode ser lida aqui e a parte 2 aqui. Antes de começarmosApós algum tempo aprendendo Golang, confesso que configurar uma ambiente funcional com go e docker não foi das tarefas mais simples. Após muita leitura e varias tentativas e erros acabei por adotar um modelo hibrido, onde uso o docker apenas para testar no ambiente mais próximo ao ambiente de produção, mas para o desenvolvimento acabei por configurar o ambiente local 😒. Assim simplifiquei bem dockercompose.yml e removi o Dockerfile que havia criado no artigo anterior. Frameworks no mundo GoO uso de frameworks em Go é viável, mas nem sempre necessário. Ao adentrar no ecossistema de Go é possível perceber o quão rico ele é, hoje mesmo sendo uma linguagem relativamente nova, é possível perceber um número enorme de opções de bibliotecas que abrangem a grande maioria das necessidades que um desenvolvedor pode ter em seu dia a dia, podendo assim tecer sua própria solução sem maiores dificuldades. Dias atrás tive acesso a um repositório que tem o intuito de catalogar e classificar os principais pacotes disponíveis para uso, pode ver ele aqui. Ele é realmente completo, tem dezenas de categorias e diversas opções para cada uma delas, certamente vale uma conferida. Ao acessar https://github.com/avelino/awesome-go#web-frameworks perceberá uma lista considerável com diversos frameworks disponíveis para o desenvolvimento de aplicações web, que será o objetivo do projeto final dessa dessa série. Desses, por indicação da própria comunidade no slack¹ ( que por sinal recomendo muito que todos que tenham interesse na linguagem participe), e baseado também em minhas pesquisas, echo e gin são os dois mais expressivos hoje. O uso de frameworks é controverso para iniciantes em uma linguagem. É fácil perceber como eles podem dar aquele gás para quem ainda está iniciando, mostrando bons caminhos, boas escolhas de design para a aplicação e muito mais. Porém é comum ver eles sendo usados como muleta para desenvolvedores que realmente não aprenderam sobre a linguagem e seu ecossistema. Assim cabe a quem esta iniciando a escolha, ou usa ele como escada ou como muleta, eu prefiro usar como escada, e esse processo me ajuda muito a aprender e me ambientar. Entre os frameworks destacados muitas similaridades são perceptíveis, tanto o echo como o gin tem um foco muito claro em performance, chegando a prometer performance ainda maior que teríamos se usarmos o módulo nativo. E isso faz muito sentido, se um dos maiores diferenciais da linguagem é a alta performance, é natural que os frameworks que compõem seu ecossistema também sigam a mesma linha. Nesse ponto é fundamental que leiam a documentação dos frameworks que parecem mais promissores, com a documentação poderá alinhar se os objetivos e funcionalidades do mesmo alinham com as do projeto. Implementando uma API em GolangBom agora é hora da parte legal, bora colocar a mão na massa e criar uma API restfull para entender melhor os desafios e as possibilidades que o ecossistema de Go disponibiliza. O objetivo da api é simular um microservice de autenticação extremamente simplista e sem nenhuma pretensão de levá-lo para produção. As principais features esperadas para essa implementação são: Cadastro de um novo usuário Atualização de usuário já cadastrado Remoção de usuário existente Listagem com todos os usuários cadastrados Validar um usuário por seu nome de usuário e senha Para essa implementação resolvi usar o echo como suporte para me prover as funcionalidades básicas para desenvolver essa API. Iniciando um novo projetoPara iniciar um novo projeto go, já dentro da nova pasta crie um arquivo de nome main.go e inclua o seguinte conteúdo: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124package mainimport ( \"net/http\" \"golang.org/x/crypto/bcrypt\" \"github.com/labstack/echo\")type User struct { Email string `json:\"email,omitempty\" form:\"email\"` Password string `json:\"-\" form:\"password\"` Name string `json:\"name,omitempty\" form:\"name\"` Role string `json:\"role,omitempty\" form:\"role\"`}var users []User// Retorna a listagem de todos os usuários cadastradosfunc getAllUsers (c echo.Context) error { return c.JSON(http.StatusOK, users)}// Retorna os dados de um usuáriofunc getUser (c echo.Context) error { email := c.Param(\"user\") user := getUserByEmail(email) return c.JSON(http.StatusOK, user)}// Cadastra um novo usuáriofunc createUser (c echo.Context) error { password := c.FormValue(\"password\") hashPassword, _ := bcrypt.GenerateFromPassword([]byte(password), 10) user := User{Email: c.FormValue(\"email\"), Password: string(hashPassword), Name: c.FormValue(\"name\"), Role: c.FormValue(\"role\")} users = append(users, user) return c.JSON(http.StatusCreated, user)}// Atualiza um usuário existentefunc updateUser (c echo.Context) error { email := c.Param(\"user\") for index, user := range users { if (user.Email == email) { name := c.FormValue(\"name\"); if ( name != \"\") { users[index].Name = name } role := c.FormValue(\"role\"); if ( role != \"\") { users[index].Role = role } password := c.FormValue(\"password\"); if ( password != \"\") { hashPassword, _ := bcrypt.GenerateFromPassword([]byte(password), 10) users[index].Password = string(hashPassword) } return c.JSON(http.StatusOK, users[index]) } } return c.JSONBlob(http.StatusBadRequest, []byte(\"{\\\"status\\\": \\\"error\\\"}\"))}// Exclui um usuário existentefunc deleteUser (c echo.Context) error { email := c.Param(\"user\") for index, user := range users { if (user.Email == email) { users = append(users[:index], users[index+1:]...) return c.JSONBlob(http.StatusOK, []byte(\"{\\\"status\\\": \\\"success\\\"}\")) } } return c.JSONBlob(http.StatusBadRequest, []byte(\"{\\\"status\\\": \\\"error\\\"}\"))}// Faz a autenticação de um usuáriofunc authUser (c echo.Context) error { email := c.FormValue(\"email\") password := c.FormValue(\"password\") user := getUserByEmail(email) err := bcrypt.CompareHashAndPassword([]byte(user.Password), []byte(password)) if (err == nil) { return c.JSONBlob(http.StatusOK, []byte(\"{\\\"status\\\": \\\"success\\\"}\")) } return c.JSONBlob(http.StatusUnauthorized, []byte(\"{\\\"status\\\": \\\"error\\\"}\"))}// Retonar instancia do usuário apartir de um e-mailfunc getUserByEmail(email string) User { var user User; for _, user = range users { if (user.Email == email) { return user } } return user;}func main() { // Inicia usuário password, _ := bcrypt.GenerateFromPassword([]byte(\"123456\"), 10) users = append(users, User{Email:\"ronaldo@test.com\", Password: string(password), Name:\"Ronaldo Meneguite\", Role:\"Admin\"}) router := echo.New() v1 := router.Group(\"/v1\") // User API v1.GET(\"/users\", getAllUsers) v1.GET(\"/users/:user\", getUser) v1.POST(\"/users\", createUser) v1.PUT(\"/users/:user\", updateUser) v1.DELETE(\"/users/:user\", deleteUser) // Auth API v1.POST(\"/auth\", authUser) router.Logger.Fatal(router.Start(\":8080\"))} E execute o seguinte comando: 1dep init Após o processo é esperado que seja criado na pasta corrente uma nova de nome vendor que contém as dependências do projeto, e dois novos arquivos Gopkg.toml e Gopkg.lock, onde o Gopkg.toml será responsável por manter o registros das dependências diretas do projeto e o Gopkg.lock de armazenar as versões de todos os packages instalados atualmente. Feito o processo, já temos nossa primeira API pronta para ser executada. Para isso execute o comando: 1go run main.go Assim feito já teremos nossa API rodando no endereço http://localhost:8080. Como puderam perceber, trabalhar com Golang não tem muitos mistérios, é certamente uma linguagem muito promissora e possui tempos de resposta realmente impressionantes, como pode ser visto abaixo: Levando nossa API a ProduçãoBom com tudo pronto e rodando localmente é hora de ver como seria colocar uma aplicação desenvolvida em Go em produção. Para isso decidi usar a Google Cloud Platform usando o serviço de App Engine. Esse artigo não tem o intuito de mostrar como fazer todo o processo de deploy usando o Google Cloud Platform, assim me limitarei a demostrar os processos feitos dentro do projeto para coloca-lo em produção e descrever minha experiência com o processo. Depois de criar o projeto no console é necessário criar um arquivo de nome app.yaml que deve possuir o seguinte conteúdo: 12runtime: goenv: flex E executar o seguinte comando: 1gcloud app deploy Após alguns minutos já terá uma sua API completamente funcional e em produção, e o que parece magica por tanta simplicidade, na verdade é um casamento perfeito entre o sistema de deploy do Google e sua linguagem. ConclusãoHoje ainda não me vejo conseguindo uma produtividade próxima da que tenho em PHP ou Javascript em Golang, principalmente em projetos monolíticos maiores, mas acho que esse jogo pode mudar muito a medida que os microservices entram em cena. Go parece nascer perfeito para esse fim, é confiável, rápido, simples e altamente escalável, certamente foi uma excelente aquisição para minha “caixa de ferramentas” e espero ter oportunidade de trabalhar diretamente com ela em breve. ¹ Para entrar no slack da comunidade acesse o link https://invite.slack.golangbridge.org. No canal **brazil** vai encontrar muitos brasileiros e pode seguir com seu idioma, porém caso se sinta-se a vontade com o inglês, o canal **general** é ainda mais ativo :)","link":"/2017/11/15/golang-desbravando-uma-linguagem-de-programacao-parte-3/"},{"title":"Publicar um site com Github Pages e CloudFlare","text":"Nesse artigo pretendo apresentar como publicar um site estático com domínio próprio, HTTPS, Cache, proteção DDOS e o melhor, de forma totalmente gratuita usando Github Pages e CloudFlare. Essas instruções são também válidas para aplicações mais complexas como uma SPA (Single Page Application) por exemplo. Já a algum tempo percebo que muitas pessoas usam linguagens dinâmicas para produção de sites estáticos, pela simples motivação de buscar um reaproveitamento do código, já vi e até mesmo já fiz isso. Hoje com o frontend cada vez mais inteligente podemos gerar interfaces extremamente ricas sem ao menos a necessidade de um servidor dinâmico próprio, apenas servindo HTML de forma estática e deixando toda interatividade do lado do cliente. Hoje, até mesmo plataformas como o Wordpress, Joomla e Drupal podem ser substituídas, em alguns casos, por geradores de sites estáticos como Jekyll, Hexo, ou Hugo por exemplo, que a partir de dados dinâmicos podem gerar sites “estáticos” e reduzir consideravelmente o custo com servidores dinâmicos, escalando aplicações de uma forma muito mais simples, com uma performance incrível e um custo de hospedagem mínimo, ou como no exemplo desse artigo, a custo zero. Entenda que não estou de forma alguma dizendo que sites estáticos são a bala de prata para resolver todos os seus problemas, mas sem dúvida ter uma visão sobre eles e perceber o valor dessa abordagem em alguns momentos pode ser um diferencial em sua carreira. Pensando nisso e para atender alguns questionamentos que vinham me fazendo há algum tempo, resolvi escrever este artigo, que pretende demonstrar uma forma muito simples de publicar um site de forma profissional e totalmente gratuita, com domínio próprio, deploy automatizado, cache habilitado, proteção DDOS, certificado HTTPS válido e muitas outras demandas de um site realmente profissional. Para atender essa demanda, vamos nos utilizar de uma composição de ferramentas muito conhecidas no mercado, como o Github Pages e Cloudflare para prover toda a estrutura necessária para disponibilizar nosso site na internet. Para entender todo o conteúdo desse artigo é importante possuir conhecimentos básicos de versionamento usando o Git, e o ter instalado em sua máquina para que possa interagir com o github. Além disso vai precisar de uma conta no Github e uma no CloudFlare, caso não tenha pode providenciar com bastante facilidade, pois são ambas gratuitas e muito úteis para um desenvolvedor. Criando um repositório no Github PagesO primeiro passo para iniciarmos, é criar um repositório ao qual irá hospedar nosso site junto ao github, pressuponho que já tenha uma conta por lá, mas caso não tenha ainda é bem tranquilo de cadastrar uma, e para projetos públicos é totalmente gratuita. Já logado em sua conta você ira criar um novo repositório no canto superior direito, como pode ser visto nas imagens abaixo: Escolha um prefixo válido e único dentro do domínio github.io, para esse exemplo vou usar meu domínio pessoal que por completa falta de tempo está abandonado mesmo 😄. Após esse processo irá visualizar uma tela similar a essa: Agora precisamos iniciar nosso repositório para habilitá-lo no github pages, para isso vamos seguir os comandos para inicializar nosso repositório. 1234567echo \"# My personal site\" >> README.mdgit initgit add README.mdgit commit -m \"First Commit\"git remote add origin git@github.com:meneguite/meneguite.github.io.gitgit push -u origin master Após esse processo, é esperado que ao acessar seu repositório novamente visualize algo como: Agora já estamos prontos, se acessar seu endereço, no meu caso https://meneguite.github.io, já deve encontrar seu site já com https rodando normalmente. Assim é hora de avançar :). Preparando o site ao qual iremos publicarO segundo passo em nossa jornada será obter um site estático para usarmos de exemplo, durante esse artigo usarei o Hielo (https://templated.co/hielo), um template gratuito que utilizarei apenas para demonstrar a publicação durante esse artigo. Pelo link https://templated.co/hielo/download baixei um arquivo zip que descompactei na pasta do projeto e removi o arquivo inicial README.md que criamos no passo anterior para testes. A estrutura dos arquivos ficou assim: Agora vamos atualizar nosso repositório e publicar nosso novo site, para isso executaremos os seguintes comandos: 123git add .git commit -m \"Include new site implementation\"git push -u origin master Com esses comandos acima você já tem um deploy automatizado, bastando atualizar seu repositório e seu site já estará atualizado. Prontinho, nosso site já está no ar e completamente funcional, já é um endereço válido e se não possuir um domínio próprio já pode usar dessa forma sem maiores problemas. Configurando o DNS do seu domínio na CloudflareAgora precisamos de uma conta na CloudFlare, é um cadastro bastante simples, não terá nenhum problema em seguir o fluxo de cadastro deles, assim que terminar o processo irá entrar no dashboard onde poderá cadastrar seus domínios como imagem abaixo: Ao clicar em “+ Add Site” seguirá o seguinte fluxo: Selecione o plano mais indicado para a sua necessidade: E confirmar o plano selecionado novamente : Se já usa seu domínio em outro provedor de DNS nesse momento a CloudFlare irá buscar todos os registros atuais para que possa administra-los dentro de sua conta, no meu caso eu removi todos os registros do DNS o que deixou da seguinte forma: Agora precisamos adicionar dois registros, seu domínio principal e um para o subdomínio www, assim independente da forma que vier o acesso o mesmo será redirecionado corretamente. Eles devem ficar assim: A CloudFlare tem uma feature bem bacana no seu DNS chamada de CNAME Flattening que possibilita criar um CNAME para o root de um domínio. (Pode ler mais informações sobre isso em https://support.cloudflare.com/hc/en-us/articles/200169056-CNAME-Flattening-RFC-compliant-support-for-CNAME-at-the-root) Após configurado será lhe apresentado a seguinte tela: Nessa tela recebemos a solicitação de alterar o endereço de DNS junto ao nosso provedor do domínio. Esse passo varia de acordo com cada provedor, mas normalmente é bastante simples.. basta alterar o endereço dos servidores de DNS atuais para esses novos endereços. ** Precisa se atentar que está transferindo o DNS autoritativo para o serviço do CloudFlare e precisa ajustar registros como o MX para que não tenha nenhum problema na migração de seus e-mails por exemplo. Após alterar os endereços de DNS junto ao seu provedor, a propagação do mesmo pode demorar um tempo para acontecer, no caso do registro.br é indicado que pode demorar até 2 horas para essa transição. Ajustes finais para nosso domínioAinda dentro da cloudflare vamos acessar nosso domínio para finalizar alguns configurações adicionais bem importantes. A primeira aba que vamos alterar é a de Crypto. Dentro dessa aba devemos nos certificar que está configurado para Full, esse já é o padrão e provavelmente não tera que alterar nada. Após esse processo devemos habilitar o redirecionamento de HTTP para HTTPS por padrão, assim qualquer acesso vindo ao nosso site será redirecionado. Otimizações na entrega de conteúdoApós as configurações básicas passadas acima existem outras que podemos fazer para otimizar nosso site, esses passos são opcionais, mas podem ajudar bastante a aumentar a performance de sua aplicação. Na aba Speed, vamos encontrar algumas configurações para otimizar a entrega de conteúdo, a principal delas é a minificação dos assets de sua aplicação de forma automática, o que é extremamente útil. Existem diversas outras opções muito interessantes como o Rate Limiting que fica na aba de Firewall, que pode ser configurado também mas que não são tão importantes nesse momento, mas não deixe de dar uma olhada com mais calma em todas as opções que a CloudFlare disponibiliza. Após concluída a migração do DNS é esperado que seja mostrado essa mensagem na tela inicial do seu domínio dentro CloudFlare. Migrando sua Github Page para seu domínio definitivoApós finalizada a configuração necessária dentro da CloudFlare chegou a hora de transferir sua Github Page para o seu domínio. O processo é bastante simples, dentro do seu repositório no Github acesse a aba Settings, alterando em Custom domain para seu domínio como abaixo: Tudo correndo bem no processo, já temos nosso site no ar com o certificado SSL implementado, e com toda infraestrutura necessária para um site de pequeno e até de médio porte. Por hoje é isso, espero que esse artigo lhe seja útil. Qualquer dúvida ou sugestões de melhora deixe aqui nos comentários.","link":"/2018/11/10/publicar-um-site-com-github-pages-e-cloudflare/"},{"title":"Observer Pattern - Design Patterns com Typescript","text":"O Observer pattern é um dos padrões de projeto mais úteis, amplamente utilizado, especialmente no frontend com os novos frameworks/libraries reativas como Vue, React e Angular por exemplo, assim, entender bem seus conceitos e o problema que ele pretende resolver, é fundamental para que possamos usá-lo da melhor forma possível. O que é o observer pattern afinal?O Observer pattern é um padrão comportamental, assim como State, Iterator e Strategy (outros padrões de projetos que ainda vamos ver durante essa série de artigos), e como a maioria dos padrões desta categoria, trata da comunicação entre objetos. Por definição, o padrão Observer define uma dependência um-para-muitos entre objetos, que ao mudar o estado de um objeto (Subject), todos os observadores (Observers) são notificados e atualizados automaticamente, sendo que de uma forma mais simplista, a ideia é fazer com que uma mudança em um objeto do interesse de muitos (Subject) ao ser modificado, notifique a todos os interessados (Observers) sobre essa mudança, transferindo seu novo estado. Abaixo um diagrama que representa esse fluxo: Como tenho tentado nessa série de artigos, vou fazer o possível para trazer neste um exemplo mais concreto, mais fácil de perceber o problema que o padrão resolve, e como podemos implementar ele, de uma forma bem simplificada, mas que já vai lhe dar uma boa base de seu funcionamento. Para exemplificar, vamos usar um exemplo de um sistema de controle de temperatura, onde temos um sensor que lê a temperatura, e duas classes Fan (Ventilador) e TemperatureDisplay que dependem dessa informação do sensor para executar alguma ação, assim vamos implementar primeiro uma solução mais simplista para identificar o problema, depois implementamos o padrão Observer, bora ao código 😉. Primeiro precisamos definir o sensor: 12345678910111213141516171819202122232425interface TemperatureSensor { getTemperature(): Number;} class ArduinoTemperatureSensor implements TemperatureSensor { protected temperature: Number = 0; constructor() { setInterval(this.setNewTemperature.bind(this), 2000); } public getTemperature(): Number { return this.temperature; } protected setNewTemperature() { const randomTemperature = Math.floor(Math.random() * 120); console.info(`New Temperature: ${randomTemperature}`); this.setTemperature(Math.floor(randomTemperature)); } protected setTemperature(temperature: Number) { this.temperature = temperature; }} Uma implementação bem simples apenas para ilustrar, sendo que definimos um método “setNewTemperature” chamado a cada 2 segundos e que gera uma temperatura randômica para o sensor. Agora precisamos criar as classes que vão usar esse sensor: 12345678910111213141516171819202122232425262728293031323334353637class Fan { protected temperatureSensor: TemperatureSensor; protected running: boolean = false; constructor(temperatureSensor: TemperatureSensor) { this.temperatureSensor = temperatureSensor; setInterval(this.monitorTemperature.bind(this), 100); } public update(temperature: Number) { console.info(`Fan read temperature ${temperature}`); if (temperature < 50) { return this.turnOff(); } return this.turnOn(); } protected monitorTemperature() { const temperature = this.temperatureSensor.getTemperature(); this.update(temperature); } protected turnOn () { if (!this.running) { this.running = true; console.info('Fun started'); } } protected turnOff () { if (this.running) { this.running = false; console.info('Fun stoped'); } }} A classe Fan simula um ventilador, recebendo um sensor, e sempre que a temperatura atingir um valor maior que 50º, o mesmo é acionado, e desligado sempre que a temperatura for menor que esse valor. 1234567891011121314151617class TemperatureDisplay { protected readonly temperatureSensor: TemperatureSensor; constructor(temperatureSensor: TemperatureSensor) { this.temperatureSensor = temperatureSensor; setInterval(this.monitorTemperature.bind(this), 100); } public update (temperature: Number) { console.info(`Display: ${temperature}`); } protected monitorTemperature() { const temperature = this.temperatureSensor.getTemperature(); this.update(temperature); }} A classe TemperatureDisplay é ainda mais simples, apenas imprime no console a temperatura aferida pelo sensor. Assim poderíamos usar essas classes da seguinte forma: 123const arduinoTemperatureSensor = new ArduinoTemperatureSensor();const fan = new Fan(arduinoTemperatureSensor);const temperatureDisplay = new TemperatureDisplay(arduinoTemperatureSensor); Ao rodar esse código, alguns aspectos ficam muito claros: Uma classe que utiliza o sensor, tem sua precisão diretamente dependente da frequência que consulta o sensor; Fica claro também que se um número muito grande de objetos dependerem do sensor, teremos uma sobrecarga no sensor, talvez até atrapalhando função principal que seria capturar a temperatura; Para cada nova classe que precisa dos dados do sensor vamos precisar implementar uma nova lógica para garantir a precisão necessária para sua atualização; Assim, o padrão Observer, entra em cena exatamente para resolver esses e outros problemas introduzidos pela abordagem anterior. Implementando o Observer PatternPara implementação do padrão precisamos definir duas interfaces, Observer e Subject. 123456789interface Observer { notify(temperature: Number): void;}interface Subject { registerObserver(observer: Observer): void; unregisterObserver(observer: Observer): void; notifyObservers(): void;} Vamos agora estender nossa interface de TemperatureSensor para que possa se comportar como um Subject: 123interface TemperatureSensor extends Subject { getTemperature(): Number;} E alterar nosso sensor para essa nova interface: 1234567891011121314151617181920212223242526272829303132333435class ArduinoTemperatureSensor implements TemperatureSensor { protected temperature: Number = 0; protected observers: Observer[] = []; constructor() { setInterval(this.setNewTemperature.bind(this), 2000); } public registerObserver(observer: Observer): void { this.observers.push(observer); } public unregisterObserver(observer: Observer): void { this.observers = this.observers.filter(o => o !== observer ) } public notifyObservers(): void { this.observers.forEach((observer) => observer.notify(this.getTemperature())); } public getTemperature(): Number { return this.temperature; } protected setNewTemperature() { const randomTemperature = Math.floor(Math.random() * 120); console.info(`New Temperature: ${randomTemperature}`); this.setTemperature(Math.floor(randomTemperature)); } protected setTemperature(temperature: Number) { this.temperature = temperature; this.notifyObservers(); }} Reparem agora como a implementação das classes que dependem do sensor fica muito mais simplificada e precisa: 1234567891011121314151617181920212223242526272829303132class Fan implements Observer { protected temperatureSubject: Subject; protected running: boolean = false; constructor(temperatureSubject: Subject) { this.temperatureSubject = temperatureSubject; this.temperatureSubject.registerObserver(this); } public notify(temperature: Number) { console.info(`Fan read temperature ${temperature}`); if (temperature < 50) { return this.turnOff(); } return this.turnOn(); } protected turnOn () { if (!this.running) { this.running = true; console.info('Fan started'); } } protected turnOff () { if (this.running) { this.running = false; console.info('Fan stoped'); } }} 123456789101112class TemperatureDisplay implements Observer { protected readonly temperatureSubject: Subject; constructor(temperatureSubject: Subject) { this.temperatureSubject = temperatureSubject; this.temperatureSubject.registerObserver(this); } public notify(temperature: Number) { console.info(`Display: ${temperature}`); }} Podemos assim executar como antes: 123const arduinoTemperatureSensor = new ArduinoTemperatureSensor();const fan = new Fan(arduinoTemperatureSensor);const temperatureDisplay = new TemperatureDisplay(arduinoTemperatureSensor); Como puderam perceber com essa mudança de abordagem, ganhamos uma precisão muito superior, fazendo com que todos objetos que dependam dos dados do sensor sejam atualizado imediatamente após uma nova leitura do sensor, além disso temos algumas outras vantagens, como por exemplo a simplificação das classes que precisam dos dados do sensor e principalmente removemos o acoplamento entre os objetos, fazendo com que interajam normalmente, porém conhecendo muito pouco um do outro. O Código completo para esta implementação pode ser encontrado em: https://github.com/meneguite/typescript-design-patterns/blob/master/observer/index.ts Outros padrões de Projetos Adapter Pattern Observer Pattern","link":"/2019/06/23/design-patterns-com-typescript-observer/"},{"title":"Como remover arquivos antigos do slack","text":"O Slack é uma ferramenta fantástica, se fazendo cada vez mais presente no dia a dia de empresas de todos os portes, seu plano gratuito é muito bom, já atentendo atender a demanda da grande maioria de empresas de pequeno porte, porém ele tem uma limitação bem chata, ao atingir o limite de armazenamento, hoje quando escrevo esse artigo 5GB, você precisa remover arquivo a arquivo em um processo extremamente manual e desestimulante. Nesse artigo pretendo mostrar um utilitário open source que desenvolvi e que irá lhe permitir executar esse processo de forma automática apenas passando o período que deseja remover os arquivos. O processo de remoção manual do slack é irritante, e como desenvolvedor que sou, detestaria fazer um processo manual como esse, ainda mais se tenho outra saída melhor para isso, assim resolvi escrever um utilitário, e posteriormente esse artigo, para demonstrar como podemos fazer esse processo em poucos passos, o que poderá te poupar várias horas limpando arquivos de seu workspace no slack. Para iniciarmos vamos precisar criar um token legacy no endereço https://api.slack.com/custom-integrations/legacy-tokens, bastando para isso gerar um novo token, caso já não o tenha gerado um até então. É esse token que irá lhe permitir executar essas ações em seu workspace. Para executar o utilitário vai precisar ter instalado em sua maquina uma versão recente do node, se já não possui ele por ai, a instalação é bem simples e encontrara todos os passos necessários em https://nodejs.org/, por aqui estou usando a versão 10, a LTS no momento que escrevo o artigo, mas provavelmente não vai ter problemas para rodar esse utilitário em versões mais recentes. Com o node instalado vamos instalar nosso utilitário: 1npm install slack-remove-files -g Após o processo é só executar o comando: 1slack-remove-files 12 months {SEU_TOKEN_AQUI} Nesse exemplo, irá remover todos os arquivos anteriores a 12 meses, mas não se limite ao exemplo, variando o valor e unidade pode personalizar como quiser e lhe atender melhor, alguns outros exemplos de combinação: 12slack-remove-files 60 days {SEU_TOKEN_AQUI}slack-remove-files 2 years {SEU_TOKEN_AQUI} Fique a vontade para criar sua combinação, antes de executar ele irá lhe solicitar uma confirmação mostrando a data apurada como pode ser visto abaixo: 12All files dated less than will 2017-08-03T16:57:04.626Z be removed. Do you wish to continue ? (y ou n) Apenas se confirmar é esperado que ele busque junto ao slack todos os arquivos e remova um a um, apresentando um relatório dos arquivos removidos como mostrado na imagem abaixo: O Código completo para desse utilitário pode ser encontrado em: https://github.com/meneguite/slack-remove-files Espero que lhe seja útil! Caso tenha alguma dúvida sobre o uso, pode deixar por aqui, ou o que seria ainda melhor, usando as issues do github.","link":"/2019/08/02/como-remover-arquivos-antigos-do-slack/"},{"title":"PWA - More than Web Apps, Progressive Web Apps!","text":"Falar sobre PWA é algo que sempre curto bastante, e ontem tive a oportunidade de apresentar uma talk em nosso grupo do GDG (Google Developer Groups) Cataguases, onde tentei passar minha visão sobre esse tema e demonstrar o quão relevante será seu futuro ( o presente também é claro :) ), passando os conceitos envolvidos no tema, bem como ferramentas e soluções que o completam e fazem das progressive web apps, ao meu ver, o futuro da esmagadora maioria das aplicações. Abaixo deixo os slides da talk, feedback são sempre bem vindos ;)","link":"/2019/09/09/pwa-processive-web-apps/"},{"title":"Quando não usar o MongoDb","text":"MongoDb é uma solução incrível, e tenho visto ganhar mercado de forma surpreendente, as facilidades e simplificação no fluxo de desenvolvimento acaba arrebatando o coração de muitos desenvolvedores, porém o que me preocupa, e o motivo que me fez escrever esse artigo, é que talvez está ganhando um mercado e sendo usado em lugares que muito provavelmente ele não é adequado. Sempre ao escolher uma tecnologia é extremamente importante se levar em consideração as limitações e propósitos da mesma, isso vai com certeza evitar uma enorme dor de cabeça no futuro. Antes de seguirmos gostaria de deixar bem claro que não tenho nada contra o MongoDb, ao contrário, uso extensivamente ele em muitos projetos nos quais ele é aderente, mas ele não é uma bala de prata para resolver todos os problemas, saber onde e quando usá-lo é muito importante. Outro ponto que gostaria de deixar claro é que muitos itens que irei levantar aqui cabem a outros bancos NoSql, direciono ao MongoDb apenas por ser a tecnologia que percebo estar mais associada a esses “errors” na escolha de storage de dados, muitas vezes sendo usado apenas como um banco relacional. Eric Evans no livro Domain-Driven Design de 2015 escreveu “The problem is not the relational databases, but when you use then for everything” em uma tradução livre, o problema não são os bancos de dados relacionais, mas quando você os usa para tudo. Hoje 5 anos após a publicação poderíamos falar exatamente o mesmo para bancos não relacionais e em especial para o MongoDb. Bancos NoSql como o mongoDb, são sistemas de armazenamento muito bons em resolver problemas como a escalabilidade e alta disponibilidade, em especial a escalabilidade horizontal, normalmente um grande gargalo de aplicações que usam bancos relacionais e precisam ter baixo tempo de resposta, mas são mais eficientes em armazenar objetos que não precisam ser normalizados. Quando não se deve usar o mongoDb?Quando a equipe não domina o MongoDbMongoDb não é daquelas ferramentas que da pra descobrir como funciona com o projeto andando, é necessário ao menos alguém com o domínio dos fluxos, configurações e da própria ferramenta. Caso tenha uma equipe com proficiência apenas em bases de dados relacionais e não tenha o tempo necessário para capacita-la, mongoDb não é uma boa. Desenvolver uma aplicação, configurar e manter um cluster MongoDb não são tarefas triviais e terá um penoso caminho até ter uma equipe proficiente nessas tarefas. Muitos erros e problemas associados ao MongoDb são na verdade fruto de uso inadequado do mesmo. Quando precisa garantir a integridade transacional e ACIDQuando transações atômicas e isoladas forem a única forma de resolver o problema, mongoDb não é interessante. Ainda que versões mais recentes possuam suporte a transações inclusive multi documentos como pode ser lido na documentação (https://docs.mongodb.com/manual/core/transactions/) quando sua aplicação depende disso para seu bom funcionamento é melhor evitar o uso do mongo. Na própria documentação do mongo é possível encontrar o seguinte alerta: Outras características interessantes e que precisam ser levados em consideração são a “Eventual Consistency” ou consistência eventual, onde os dados ficarão consistente em algum momento, porém não garantem a consistência o tempo todo e o “Soft-state” onde os dados não precisam ser consistentes com gravação, nem réplicas precisam ser mutualmente consistentes o tempo todo. Essas características são pontos de atenção que podem gerar problemas muito graves se não tratadas adequadamente, como por exemplo receber uma resposta não atualizada quando se busca o saldo de uma conta bancária. Quando possui uma demanda muito específicaA proposta do MongoDb é ser um banco de uso geral, ele possui quase todas as funcionalidades e características necessárias para uso de um banco de dados completo, isso certamente é um dos fatores importantes que possibilitam usar o mongo como fonte de dados principal em uma aplicação, ao contrário de outras soluções NoSql que possuem um escopo muito mais especializado. Considerando que o mongo precisa atender a grande maioria dos cenários do dia a dia é evidente que outras soluções mais especializadas serão mais adequadas e atenderão melhor nesses cenários, assim é comum complementar o uso do mongo com outras soluções que para que se propõe, são melhores. Por exemplo: Quando possui dados que sempre são acessados apenas por uma chave, bancos chave-valor como Redis e Memcache são bem interessantes. Esses sistemas são constantemente usados para armazenamento de cache e configurações por exemplo; Quando se precisa de um sistema mais parrudo de busca talvez soluções como Elasticsearch ou Solr podem ser mais adequadas; Quando se precisa de um sistema mais confiável de filas (queues), provavelmente usar soluções mais especializadas como RabbitMQ e ZeroMq por exemplo, é melhor. Quando os dados forem claramente relacionaisMongoDb é um banco não relacional, tenha isso sempre em mente. Ainda que possua suporte a relacionamentos, não é onde ele se dará melhor. Se tem um domínio bem definido e claramente uma estrutura relacional, é melhor confiar seus dados a um gestor de banco de dados que foi criado e otimizado para manter os relacionamentos e consistência entre os mesmos. A garantia de integridade relacional no MongoDb não existe, passa a ser responsabilidade da aplicação garantir essa integridade, o que pode gerar muitos problemas de inconsciência se sua equipe não possuir maturidade para assumir essa responsabilidade. Por exemplo remover um usuário sem remover os endereços desse usuário, vai gerar uma série de registros órfãos no banco. Quando o custo de manter um cluster for um problemaManter um cluster mongo não é barato, idealmente é sugerido manter ao menos 3 instancias do cluster com máquinas não muito fracas, normalmente acima de 2GB de RAM para garantir a integridade do mesmo. É possível rodar com 2 instancias mais um arbitro, mas é um risco que normalmente não aconselho quando não se sabe exatamente o que se está fazendo. É claro que esse custo pode ser irrisório em projetos maiores e que já estejam tracionando, porém podem pesar quando se pretende apenas validar um produto, ou ainda possui um produto que não se paga. Então tenha em mente o custo total que manter um cluster mongo vai trazer para o projeto. ConclusãoO MongoDB é um banco de dados incrível e com certeza não deve ser descartado como um possível storage de dados em seus projetos, apenas certifique-se que o use onde é adequado, assim conseguira aproveitar o que de melhor o mesmo tem a oferecer e evitara problemas e dores de cabeça por uma escolha equivocada.","link":"/2021/01/01/quando-nao-usar-o-mongodb/"},{"title":"LDAP - Lightweight Directory Access Protocol","text":"Este documento tem por objetivo orientar e discorrer sobre um protocolo que, apesar de ser muito utilizado, sendo um padrão em empresas de médio a grande porte, são poucos os que realmente conhecem suas funcionalidades mais avançadas. Isso ocorre visto que soluções proprietárias tendem a abstrair esse nível de configuração, engessando um protocolo extremamente flexível, limitando-os a apenas frações de suas funcionalidades. No decorrer desse material o leitor será encaminhado por uma introdução sobre os conceitos que são necessários para o entendimento do protocolo, passando pelas implementações dessa ferramenta, hoje disponíveis no mercado; um exemplo de estudo de caso, onde a partir de uma necessidade inicial de um cliente é desenvolvido um estudo de quais ferramentas mais se adequariam aos requisitos, sempre focando a centralização das informações em uma única base LDAP. O PROTOCOLO LDAPOrigens do LDAPNo início da década de 80, ao se unirem a ISO e o CCITT com o objetivo de criar um serviço de mensagens, surgiu a necessidade de desenvolver um protocolo que tivesse a capacidade de organizar entradas em um serviço de nomes de forma hierárquica, capaz de suportar grandes quantidades de dados e com uma enorme capacidade de procura de informações. Esse serviço criado pelas duas instituições, foi apresentado em 1988, sendo denominado X.500, juntamente com um conjunto de recomendações e normas ISO 9594. O X.500 especificava que a comunicação entre o cliente e o servidor do diretório deveria usar o Directory Access Protocol (DAP) que era executado sobre a pilha de protocolos do modelo OSI. Devido à alta complexidade e o custo elevado, pesquisadores da Universidade de Michigan criaram um servidor LDAP, o slapd, que atuava sobre os protocolos TCP/IP. Este servidor foi apresentado como uma alternativa ao protocolo DAP em 1993, como citado por GOUVEIA (2005), disponibilizando as fontes na Internet e criando listas de discussão para divulgar e aperfeiçoar esse novo protocolo. Assim a evolução do mesmo foi acompanhada por pessoas do mundo inteiro, e o mesmo deixou de ser uma mera alternativa para o protocolo DAP, tornando-se um serviço de diretório completo, agora competindo diretamente com o X.500. O LDAP é um protocolo especializado em organizar os recursos de rede de forma hierárquica, através de uma árvore de diretórios, que roda sobre os protocolos TCP/IP, diferente do protocolo no qual foi baseado, o DAP, o qual roda sobre o modelo OSI. Para BARTH e SIEWERT (2009) essa foi uma das principais causas da adoção em larga escala do protocolo, visto que com essa nova plataforma foi possível reduzir consideravelmente o overhead1 de camadas superiores do modelo OSI. Segundo GOUVEIA (2005) o LDAP ganhou força após o ano de 1997, quando foi lançada sua terceira versão, além de uma fundação a qual mantém uma solução OpenSource a OpenLDAP Foudation, várias outras empresas como Novell, Microsoft e Netscape começaram a oferecer produtos baseados nessa nova plataforma. Protocolo LDAP vs X.500Segundo TRIGO (2007), o LDAP possui as seguintes simplificações em relação ao X.500: É executado diretamente sobre o TCP/IP; A maioria dos elementos de dados são representados como cadeias de caracteres, processadas de modo mais fácil que os dados na representação estruturada Abstract Syntax Notation One (ASN.1) usada pelo X.500; Codifica dados para transporte em redes usando uma versão simplificada das mesmas regras de codificação usadas pelo X.500; Elimina características pouco usadas e também operações redundantes do X.500. Figura 1: Aplicação LDAP Fonte: OpenLDAP Foundation (2009) Noções teóricas sobre o LDAPDefinições de diretóriosTRIGO (2007) descreve que diretório é literalmente definido como “algo usado para indicar direções”, ou seja, para indicar um caminho para se chegar àquilo que se procura. Segundo a definição de TUTTLE (2009): “Diretório é uma lista de informações sobre objetos organizados ou catalogados em uma ordem, e que fornece o acesso aos dados dos objetos. São os diretórios que permitem que usuários ou aplicações encontrem recursos no ambiente com as características necessárias para um tipo de tarefa particular.” Diretórios nos cercam a todo tempo, seja em uma lista telefônica, na estrutura de pastas do computador, em blogs, em serviços de buscas, além de vários outros lugares. Outro exemplo de diretório é o DNS o qual possui uma relação de nomes de host2 e seu respectivoIP. Segundo TRIGO (2007) é muito comum ocorrer confusão com o uso de diretórios,pois apesar de ser possível fazer com eles praticamente qualquer coisa, desde salvar informações como um banco de dados, salvar arquivos como um sistema de arquivos e disponibilizar arquivos como um sistema FTP, não se justifica o mesmo, pois para cada uma dessas funções existe um sistema que foi desenvolvido para fazer somente essa tarefa, assim sem dúvida, o fará muito melhor do que o diretório. Características do LDAPSegundo TRIGO (2007), o LDAP foi padronizado em junho de 1993, no RFC 1487 da IETF. O LDAP, segundo BARTH e SIEWERT (2009) foi projetado para resolver problemas de distribuição de diretórios pela rede, contando com nove aspectos que lhe garantiram essa habilidade, sendo eles: Seu desenho genérico Simplicidade do protocolo Arquitetura distribuída Segurança Padrão aberto Solicitação de funcionalidades e esquemas do servidor Internacionalização Suporte ao IPv6 Berkeley ́s Data Base (BDB) Ainda segundo BARTH e SIEWERT (2009) uma aplicação que o LDAP disponibiliza é o conceito de Single Sign On (SSO), ou seja, autenticação unificada, possibilitando e facilitando a integração com diversos outros serviços, assim o usuário tem apenas um userid ou identificação única na rede e com esse pode acessar diversos recursos da mesma. TUTTLE (2009) afirma que o LDAP é um padrão aberto capaz de facilitar, de forma flexível, o compartilhamento, a manutenção e o gerenciamento de grandes volumes de informações, definindo um método-padrão de acesso e atualização de informações dentro de um diretório.Para LOSANO (2009) a principal característica do LDAP é a integração com outros serviços, complementando assim a infra-estrutura de redes, fornecendo novos recursos e, especialmente, maior integração, diferentemente de outros protocolos e linguagens estabelecidos como exemplo: SNMP, HTTP, SMTP, IMAP ou SQL. Abaixo a figura 2 representa essa característica. Figura 2: Característica do LDAP Fonte: OpenLDAP Foundation (2009) Estrutura do LDAPTRIGO (2007) afirma que o grande fator responsável pelaflexibilidade do LDAP é a sua organização de forma hierárquica. A árvore de informações possui um elemento-raiz, por onde começa a busca das informações. A partir daí, o sistema vai percorrendo os nós filhos até que consiga encontrar o elemento desejado. A raiz e os ramos da árvore são os diretórios os quais podem conter outros diretórios. Abaixo desses diretórios estão os elementos ou também chamados de entradas. Para cada entrada podemos ter um ou mais valores associados a ela. A tabela 1 abaixo mostra os principais atributos e suas descrições. Tabela 1: Exemplos de atributos, com suas respectivas descrições: Atibuto Descrição Dc Identificação única do objeto (do inglês Distinguished Name) C Para diretórios que representam países (do inglês country) O Para o nome da empresa (do inglês organization) Ou Para departamento (do inglês organization unit) Cn Atributo de nome (do inglês common name) Uid Identidade do usuário (do inglês user id) Gn Nome próprio do usuário (do inglês given name) Segundo TRIGO (2007), existem duas maneiras de organizar uma árvore de diretórios; no estilo X.500 onde a estrutura da árvore de diretórios é baseado em regiões, como é demonstrado na figura 3 e no estilo DNS, no qual, os dados são organizados como se fossem domínios. A grande vantagem de se usar o estilo DNS é o fato de poder configurar o serviço de LDAP para uma empresa a partir de um nome de domínio válido, garantindo o caráter único da identidade quando disponibilizado através da Internet. Na figura 4 abaixo podemos visualizar uma estrutura baseada nesse estilo. Figura 3: Estrutura no estilo X.500 Figura 4: Estrutura no estilo DNS #### Schema Segundo GOUVEIA (2005), os schemas são responsáveis por manter a integridade dos dados do diretório. São extensíveis, possibilitando a adição de atributos ou classes de acordo com a necessidade. Schemas definem quais object class podem ser inseridos no diretório, quais os atributosde uma determinada object class e quais os valores possíveis para esses atributos. Assim, caso um objeto não obedeça às regras do schema, não poderá ser inserido no mesmo. Arquivos LDIFSegundo TRIGO (2007), arquivos LDIFs são arquivos de texto puro, usados para importar, modificar e exportar informações. Esse formato de arquivo é o único meio de entrada de dados em um servidor LDAP; mesmo programas que trabalham diretamente com o servidor LDAP, inserindo e removendo registros, como é o caso do PHPMyAdmin, utilizam-se de arquivos LDIF para suas transações. Abaixo é colocado dois arquivos LDIF onde o primeiro é responsável pela inserção de um usuário em uma base, e o seguinte pela modificação do valor do atributo userPassword, no caso, a senha do usuário. Arquivo insereUser.ldif 12345dn: cn=ronaldo,dc=secure,dc=inf,dc=brcn: ronaldoobjectClass: simpleSecurityObjectobjectClass: organizationalRoleuserPassword: {SSHA}4P4F2gCtCh7PthUlS1AJ+DOMXOI0iUpH description: Usuario Ronaldo Arquivo atualizaUser.ldif 1234dn: cn=ronaldo,dc=secure,dc=inf,dc=brchangetype: modifyreplace: userPassworduserPassword: {SSHA}tNnd/KF/Rg/dCTq4S1yo7OEiUK4aFk9g IMPLEMENTAÇÕES DO PROTOCOLO LDAPComo mencionado anteriormente, o protocolo LDAP é apenas um conjunto de conceitos e definições que possibilitam uma padronização na troca de informações entre diversas soluções baseadas no protocolo. Assim os métodos utilizados para armazenar as informações internamente e de replicação, por exemplo, são peculiaridades de cada implementação. Abaixo é apresentado algumas características dessas principais implementações. Active DirectoryO Active Directory é uma implementação do serviço de diretório utilizando o protocolo LDAP que armazena informações sobre objetos em redes de computadores e disponibiliza essas informações a usuários e administradores desta rede. É um software da Microsoft utilizado em ambientes Windows e que segundo SANTANA (2009) surgiu juntamente com o Windows 2000 Server. Objetos como usuários, grupos, membros dos grupos, senhas, contas de computadores, relações de confiança, informações sobre o domínio, unidades organizacionais, etc., ficam armazenados no banco de dados do AD que além de armazenar esses vários objetos em seu banco de dados, disponibiliza vários serviços, como: autenticação de usuários, replicação do seu banco de dados, pesquisa dos objetos disponíveis na rede, administração centralizada da segurança utilizando GPO, entre outros. Esses recursos tornam a administração do AD bem mais fácil, sendo possível administrar todos os recursos disponíveis na rede centralizadamente. Figura 5: Exemplo de implementação do Active Directory eDirectoryAssim como a Microsoft, a Novell também disponibiliza uma implementação do LDAP, o eDirectory, que é a base de identidade que vincula os usuários e seus direitos de acesso aos recursos, dispositivos e políticas de segurança da empresa. Ele oferece a compatibilidade, segurança, confiabilidade, escalabilidade e gerenciabilidade necessárias para distribuições internas e de Internet. O eDirectory possui características muito próximas do Active Directory da Microsoft. Figura 6: Exemplo de implementação do eDirectory Fonte: Novel (2009) OpenLDAPO OpenLDAP é uma implementação do LDAP desenvolvida pela Universidade de Michigan e mantido pelo Projeto OpenLDAP , possui como principais características: suporte ao IPv4 e IPv6, autenticação, segurança no transporte usando SSL e TSL, controle de acessos, alta performance em múltiplas chamadas e a replicação de base. O OpenLDAP tem uma licença específica chamada de The OpenLDAP Public License (OpenLDAP Project, 2009) e é independente de plataforma, assim várias distribuições Linux já disponibilizam o mesmo em seus repositórios. Além do Linux o OpenLDAP é também compatível com AIX, variantes de BSD, HP-UX, Mac OS X, Solaris e Microsoft Windows ( Baseados na tecnologia NT). Figura 7: Implementação do LDAP + phpLDAPAdmin ReplicaçãoA replicação é um método muito utilizado quando trabalhamos em um ambiente corporativo, onde existe a necessidade de alta disponibilidade nos serviços. É na verdade a manutenção de uma cópia, seja parcial ou total, dos dados em outros servidores. No OpenLDAP existem duas técnicas distintas de replicação, as quais são o slurpd e o syncrepl, sendo que a slurpd, é uma técnica mais antiga a qual foi descontinuada na versão 2.4 do OpenLDAP , por possuir uma série de limitações que foram supridas por sua sucessora a syncrepl. As principais limitações eram as limitações para replicar uma base parcialmente e a utilização de mais de um servidor Master. Quando trabalhamos com o syncrepl o servidor LDAP pode assumir duas posturas quanto à replicação, Master ou Slave. Quando Master o servidor assume todas as funções de um servidor OpenLDAP , desde a inserção, atualização e consulta dos dados. Porém quando slave o servidor só aceitará execuções de consultas em sua base de dados quando originadas de máquinas clientes, assim para que qualquer informação seja alterada, a solicitação deveráser feita ao servidor Master o qual se encarregará de replicar as alterações para seus servidores slaves. Replicação Master x Slave – Nesse método de replicação temos um único servidor Master o qual tem seu conteúdo replicado em todos os seus servidores escravos. Nesses servidores slaves não ocorre entrada de dados, apenas replicam passivamente os dados de um servidor principal. Esse método de replicação é o mais comum e atende a grande parte das demandas de servidores LDAP. Replicação Master x Master (multimaster) – Replicação multimaster é um método de replicação mais recente no OpenLDAP , porém já implementado no Active Directory desde sua primeira versão. Esta é uma replicação que atende a demandas muito singulares e apesar de funcionar muito bem ainda é pouco difundida e aplicada.Esta replicação consiste na utilização de dois ou mais servidores Masters, independentes, os quais possuem todas as suas funcionalidades ativadas, porém é criado por parte dos servidores um controle interno para que seja possível manter a integridade dos dados, algo que era muito mais simples de controlar quando existia uma única entrada de dados. Diretórios Distribuídos – Utilizando o OpenLpad com o método de replicação syncrepl podemos não somente criar uma cópia da árvore de diretórios em outros servidores, mas também criar políticas de replicação e replicar a cada servidor somente aquilo que se pretende que o mesmo tenha acesso, assim por exemplo, quando temos uma empresa com sede em Minas Gerais e filial em São Paulo, a mesma não precisa replicar toda sua base para a filial, apenas aqueles usuários que a pertençam, evitando assim um tráfego desnecessário narede além de aumentar a segurança. CriptografiaFazendo-se uso da definição de FADEL (2009): “O termo Criptografia tem origem grega e surgiu da fusão das palavras “kryptós” e “graphein”, que significam “oculto” e “escrever”, respectivamente. Trata-se de um conjunto de conceitos e técnicas que visa codificar uma informação de forma que somente o emissor e o receptor possam acessá-la, evitando que um intruso consiga interceptá-la.” Segundo TRIGO (2007), na maioria das vezes, o servidor LDAP é utilizado para armazenar dados de usuários, como senha de autenticação, por exemplo, assim segurança é algo fundamental. Para aumentarmos a segurança no transporte de dados é possível criptografá-los, usando TLS ou SSL, assim mesmo que alguém consiga interceptar os dados, não conseguirá visualizar o que está sendo trafegado. Módulos de Banco de DadosComo mencionado anteriormente o LDAP é apenas um protocolo de comunicação entre um cliente e um serviço de diretórios. A definição do armazenamento das informações da árvore de diretórios é independente do mesmo, assim cada implementação do protocolo é responsável por fazer essa definição, podendo variar desde um simples arquivo texto até um banco de dados relacional completo. Segundo TRIGO (2007), o OpenLDAP possui dois bancos de dados nativos, o LDBM e o BerkeleyDB, sendo que o segundo é para ele a melhor opção quanto ao desempenho. Listas de Controle de Acesso (ACLs)ACL é a definição de todos os recursos de acesso controlado e todos aqueles usuários que têm acesso a eles. Segundo CARTER (2009), as ACLs disponibilizadas pelo OpenLDAP possuem uma sintaxe simples, além de serem também muito flexíveis e robustas em sua implementação. A idéia básica das ACLs é definir quem tem acesso a quê. Abaixo é exposto um exemplo de ACL no OpenLDAP : 12345# ACL do Atributo userPassword Access to attrs=userPassword by self write by cn=backup,dc=secure,dc=inf,dc=br read by * auth A ACL acima tem a função de permitir que apenas o dono tenha acesso de escrita no campo userPassword, ou seja, só ele pode mudar sua senha, que o usuário cn=backup,dc=secure,dc=inf,dc=br consiga apenas ler esse atributo e que todos os demais deverão se autenticar como um usuário com permissão de acesso a esse atributo. Resumidamente a sintaxe das ACLs no OpenLDAP é: 1access to <o que> by <quem> <controle> Backups e RestauraçãoO backup e restauração de uma base LDAP é extremamente fácil, como demonstrado com os comandos abaixo: Para efetuarmos Backup de toda a base: 1slapcat > backup.ldif Retornar o backup (é necessário estarmos com a base parada) 1slapadd –l backup.ldif Existem outras maneiras de fazer os procedimentos acima relacionados. Por exemplo, usando o ldapadd, não precisamos parar o serviço do OpenLDAP para efetuarmos o retorno dos dados, porém precisaremos ter um usuário com permissão administrativa para inserir os mesmos, diferente do slapcat o qual só precisa ter acesso ao diretório do banco de dados do OpenLDAP no caminho /var/lib/ldap/. Saber definir qual o procedimento mais adequado para a necessidade do cliente é extremamente importante. ESTUDO DE CASOLevantamento de requisitosPara uma demonstração prática sobre o tema foi feito um estudo de caso da empresa Secure Info Ltda, uma empresa de consultoria na área de segurança da informação a qual está se preparando para entrar no mercado. A Secure Info possui demanda de uma série de serviços os quais pretende prover internamente, sendo eles: Servidor interno de e-mail (com soluções SMTP, POP e IMAP); Sistema gerenciador de domínio e autenticação (máquinas Windows e Linux); Servidor FTP; Sistema de Webmail; Servidor de Proxy; Servidor Web; Servidor SSH; Servidor de Arquivos. Para esta implementação foi definido como requisito a integração da autenticação entre os serviços, assim não deverá haver redundância de informações cadastrais dos usuários e lista de contatos, outro requisito é a utilização de soluções OpenSource de maneira a não dispor de recursos na aquisição de novas licenças. Este documento abordará somente a instalação e configuração dos servidores LDAP, informações sobre a instalação dos outros serviços citados podem ser encontradas no próprio website do desenvolvedor, onde normalmente já disponibilizam materiais com instruções para a instalação, como também nos livros de CARTER (2009) e TRIGO (2007). Definição de Softwares a serem usadosSistema operacionalPara a implementação destes servidores o primeiro item a ser definido é o sistema operacional que será usado, pois todos os softwares definidos posteriormente dependerão diretamente dessa definição. Diversos sistemas foram considerados nessa implementação, porém alguns como o Windows Server e Unix foram descartados por termos como requisito, um sistema OpenSource o qual não demande custo de licenças, o que não é o caso dos mesmos. Assim se enquadram nesse perfil os sistemas LINUX, porém os mesmos possuem uma infinidade de derivações, denominadas distro ou distribuições, as quais se diferenciam em diversos casos muito uma da outra, assim escolher uma distribuição que se enquadre melhor aos requisitos do projeto é fundamental para o sucesso do mesmo. As distribuições avaliadas foram: 123456Suse Linux Enterprise 11;OpenSuse 11.1;RedHat Enterprise 5.4;Fedora 11;Unbutu Server 8.04 LTS;Debian 5; Diante das distribuições avaliadas, duas inicialmente já foram descartadas por se tratarem de distribuições comerciais as quais demandam um custo elevado para aquisição da licença de uso, são elas: Suse Linux Enterprise 11 e RedHat Enterprise 5.4. Das demais, todas cumpririam os pré-requisitos identificados, assim definimos o Debian 5 como a solução a ser implementada, pois trata-se de um sistema robusto, leve, possui um gerenciador de pacotes extremamente poderoso, o APT, além de contar com um sistema massivo de testes que garantem que os softwares disponibilizados para o mesmo, estarão realmente maduros, sendo esse seu principal diferencial. Sistema Gerenciador de Domínio e AutenticaçãoPara essa definição foram considerados as três principais implementações do protocolo LDAP, o Active Directory, eDirectory e uma solução integrada entre OpenLDAP + Samba, porém a única solução que cumpre os requisitos é a junção OpenLDAP + Samba, já que os outros são proprietários e demandam um investimento alto na aquisição de suas licenças. Sistema de e-mailDiversos sistemas gerenciadores de e-mails também conhecidos como MTA estão disponíveis hoje no mercado, os principais são Microsoft Exchange, Qmail e Postfix. O Microsoft Exchange é um sistema muito bom, porém não é compatível com o sistema operacional adotado, assim restam-nos duas soluções o Qmail e PostFix, diante das mesmas optaremos pela solução Postfix a qual conta com um desenvolvimento bem mais ativo que o Qmail, além de possuir material de apoio muito bom e amplo. Servidor FTPExiste hoje uma infinidade de opções em soluções FTP, como por exemplo, proftpd, pureftp e o vsftpd, porém as mesmas possuem características muito similares sendo assim optaremos pela implementação da solução proftpd a qual atende os requisitos e possui uma maior compatibilidade de integração com o servidor de autenticação baseada no OpenLDAP. Servidor de ArquivoPara servidor de arquivo utilizaremos o SAMBA por atender os requisitos iniciais do projeto além de já estar disponível no sistema devido a necessidade do mesmo para autenticarmos os usuários na rede. Definição da divisão dos serviços entre os servidoresPara esta implementação usaremos a seguinte estrutura: Figura 8: Estrutura de divisão dos serviços entre os servidores Cada figura de servidor representa um serviço rodando dentro do respectivo servidor. Instalação do Servidor OpenLDAPRequisitos para a instalação do OpenLDAPO primeiro procedimento adotado foi a atualização dos repositórios instalados com o comando: 1apt-get update Logo depois a atualização dos pacotes instalados: 1apt-get upgrade Antes de iniciar a instalação verificamos alguns parâmetros importantes no sistema, os quais, farão grande diferença no ato da instalação do OpenLDAP . O primeiro parâmetro verificado se encontra no arquivo /etc/hosts, onde deverá ser informado o IP do servidor, nome, domínio e apelido da máquina. Foram inseridos os seguintes parâmetros logo abaixo da linha, que referencia o localhost. 12127.0.0.1 serv1.secure.inf.br serv1 192.168.239.134 serv1.secure.inf.br serv1 O segundo parâmetro verificado foi no arquivo /etc/hostname onde substituímos o nome serv1 para seu nome completo serv1.secure.inf.br. Com esses parâmetros configurados cumprimos os requisitos básicos para iniciarmos a instalação. Instalação do OpenLDAP e seus utilitáriosPara a instalação do OpenLDAP e seus utilitários utilizamos o seguinte comando: 1apt-get install slapd ldap-utils Na instalação inicial, o próprio debian cria baseado nos parâmetros os quais foram alterados anteriormente uma estrutura previa da árvore, assim não precisamos fazer esse processo manualmente. Nesta instalação a árvore em formato DNS foi criada com a raiz “dc=secure,dc=inf,dc=br”, parâmetro esse que servirá de base para todos os itens que o sucederem. O arquivo de configuração principal do OpenLDAP é o /etc/ldap/slapd.conf, este éalgo como um centro de controle do OpenLDAP e é nele que faremos várias configurações durante todo o processo de instalação do servidor. Com a base montada procedemos com o seguinte comando para verificar se o servidor OpenLDAP está de fato configurado corretamente: 1ldapsearch -x -h localhost -b \"dc=secure,dc=inf,dc=br\" O retorno foi: 123456789101112dn: dc=secure,dc=inf,dc=brobjectClass: top objectClass: dcObjectobjectClass: organization o: secure.inf.brdc: doctumdn: cn=admin,dc=secure,dc=inf,dc=brobjectClass: simpleSecurityObject objectClass: organizationalRolecn: admindescription: LDAP administrator Com esse retorno demos sequência à instalação inserindo alguns objetos na árvore, de maneira a povoá-la adequadamente. Como descrito anteriormente, a única maneira de transferir dados a um servidor LDAP é fazendo uso de arquivos do tipo ldif, assim prosseguiremos criando um arquivo, o qual será o responsável por criar alguns grupos em nossa árvore. Abaixo podemos visualizar o conteúdo do arquivo grupos.ldif : 123456789101112131415161718192021222324dn: ou=grupos,dc=secure,dc=inf,dc=br ou: GruposobjectClass: organizationalUnit objectClass: topdn: ou=usuarios,dc=secure,dc=inf,dc=br ou: GruposobjectClass: organizationalUnit objectClass: topdn: ou=ti,ou=usuarios,dc=secure,dc=inf,dc=br ou: tiobjectClass: organizationalUnitobjectClass: topdn: ou=base_teste,ou=usuarios,dc=secure,dc=inf,dc=br ou: base_testeobjectClass: organizationalUnitobjectClass: topdn: ou=administracao,ou=usuarios,dc=secure,dc=inf,dc=br ou: administracaoobjectClass: organizationalUnitobjectClass: top Para inserirmos esses grupos em nossa árvore faremos uso do seguinte comando: 1ldapadd -h localhost -x -D cn=admin,dc=secure,dc=inf,dc=br -w senha -f grupos.ldif Para a inserção de usuários usaremos o arquivo usuarios.ldif descrito abaixo: 12345678910111213141516171819202122232425262728dn: uid=ronaldo,ou=ti,ou=usuarios,dc=secure,dc=inf,dc=bruid: ronaldocn: Ronaldo Meneguitesn: MeneguiteobjectClass: inetOrgPerson objectClass: posixAccount homeDirectory: /home/ronaldo loginShell: /bin/bash uidNumber: 1000gidNumber: 1000userPassword: {SSHA}sZmrhpFA7XTkVGVrljx7QiUqU8kFLMlo dn: cn=replicator,dc=secure,dc=inf,dc=brcn: replicatorobjectClass: simpleSecurityObjectobjectClass: organizationalRoleuserPassword: {SSHA}sZmrhpFA7XTkVGVrljx7QiUqU8kFLMlo description: LDAP Replicatordn: uid=estagio,ou=ti,ou=usuarios,dc=secure,dc=inf,dc=br uid: estagiocn: Estagiariosn: EstagiaroobjectClass: inetOrgPersonobjectClass: posixAccounthomeDirectory: /home/estagiologinShell: /bin/bashuidNumber: 1002gidNumber: 1000userPassword: {SSHA}sZmrhpFA7XTkVGVrljx7QiUqU8kFLMlo Para inserirmos esses grupos em nossa árvore faremos uso do seguinte comando: 1ldapadd -x -D cn=admin,dc=secure,dc=inf,dc=br -w senha -f usuarios.ldif Com o comando abaixo, podemos verificar se os grupos e usuários foram inseridos com sucesso. 1ldapsearch –x –b =secure,dc=inf,dc=br Com sucesso nos comandos acima, foi listado todo o conteúdo do diretório LDAP inclusive com os grupos e usuários inseridos anteriormente, tendo assim em mãos um servidor OpenLDAP configurado e pronto para usar. Para o segundo servidor o serv2.secure.inf.br foi efetuado o mesmo procedimento de instalação do serviço, não inserindo os usuários e grupos como no servidor principal, visto que os mesmos serão replicados quando configurarmos a replicação. Ativando suporte a criptografiaO servidor OpenLDAP suporta trabalhar com dois esquemas de criptografia sendo eles, o SSL ou TLS onde a diferença entre eles é que o SSL por ser uma camada de segurança, tem sua porta alterada para uma porta diferente da padrão, a 389, enquanto no TLS, a criptografia é feita na camada de transporte, o que propicia ser ativado sem alteração da porta do serviço. A resistência da criptografia quando em ataque, tanto na SSL quanto do TLS ébasicamente a mesma, visto que ambos são fornecidos pelo OpenSSL. Para este estudo de caso utilizaremos o TLS como método de criptografia. Ativando suporte a TLSPara ativar o suporte a TLS será usado a seguinte sequência de comandos: 123456789101112131415161718192021# Instalar o OpenSSLapt-get install openssl# Criar o diretório para armazenamento da chavemkdir /etc/ldap/tlscd /etc/ldap/tls# Criando a agência certificadora/usr/lib/ssl/misc/CA.sh –newca# Criando certificado do servidor:openssl req –new –nodes –keyout newreq.pen –out newreq.pem# Assinando o certificado do servidor com o da agência certificadora criada:/usr/lib/ssl/misc/CA.sh –sign# Alterando os nomes dos certificados gerados para facilitar a identificação:mv newcert.pem srvcert.pem mv newreq.pem srvkey.pem# Copiando o certificado da agência certificadora para o mesmo diretórios dos outros: cp demoCA/cacert.pem . Ativando TLS no OpenLDAPPara ativarmos o suporte a TLS no OpenLDAP devemos adicionar no arquivo /etc/ldap/slapd.conf as seguintes linhas logo após a inclusão dos schemas: 123TLSCertificateFile /etc/ldap/tls/srvcert.pemTLSCertificateKeyFile /etc/ldap/tls/srvkey.pemTLSCACertificateFile /etc/ldap/tls/cacert.pem Após a inserção das linhas acima mencionadas reiniciamos o servidor com o seguinte comando: 1/etc/init.d/slapd restart Para testarmos a comunicação criptografada, prosseguimos com a configuração do cliente LDAP, sendo ele instalado junto com o servidor, de maneira que o mesmo possa utilizar TLS, bastando para isso inserirmos no final do arquivo a seguinte linha: 1TLS_CACERT /etc/ldap/tls/cacert.pem Para visualizamos o funcionamento da criptografia, faremos uso do seguinte comando: 1ldapsearch –x –ZZ Para futuro uso copiaremos os certificados gerados para a pasta /etc/ldap/tls/ do serv2.secure.inf.br. ReplicaçãoComo descrito anteriormente existe hoje duas maneiras de fazermos uma replicação utilizando o OpenLDAP , uma é usando o slurpd e outra usando o syncrepl, porém o slurpd foi descontinuado na versão 2.4 do OpenLDAP , além de possuir uma série de limitações. Assim foi definido a utilização do syncrepl. Configurando o serv1.secure.inf.br (MASTER)Foi iniciado a configuração do servidor Master alterando o arquivo de configuração /etc/ldap/slapd.conf, alterando o parâmetro modulepath para syncprov e inserindo as seguintes linhas logo abaixo da opção “índex”: 123overlay syncprov syncprov-checkpoint 100 10 syncprov-sessionlog 100 Inserimos também junto a ACL responsável pelos atributos de senha, userPassword e shadowLastChange a seguinte linha: 1by dn=\"cn=replicator,dc=secure,dc=inf,dc=br\" read Assim inserimos a permissão para o usuário replicador ler os campos de senha dos usuários, pois sem o acesso a leitura ele não conseguiria efetuar a replicação completa da base. Neste ponto foi reiniciado o servidor com o comando: 1/etc/init.d/slapd restart Configurando o serv2.secure.inf.br (SLAVE)Iniciamos a configuração do servidor slave editando o arquivo de configuração /etc/ldap/slapd.conf e removendo o caracter # antes da linha “rootdn”, e logo após inserimos as seguintes linhas abaixo de “index”: 12345678910111213syncrepl rid=1 provider=ldap://serv1.secure.inf.br:389 type=refreshAndPersist retry=\"5 + 5 +\" interval=00:00:00:10 searchbase=\"dc=secure,dc=inf,dc=br\" filter=\"(objectClass=*)\" scope=sub attrs=\"*\" schemachecking=on bindmethod=simple binddn=\"cn=replicator,dc=secure,dc=inf,dc=br\" credentials=doctum2009 Após os procedimentos acima citamos, inserimos a linha “TLS_CACERT /etc/ldap/tls/cacert.pem” no aquivo /etc/ldap/ldap.conf , paramos o servidor OpenLDAP , removemos os diretórios e novamente iniciamos o servidor, para isso utilizamos as seguintes linhas de comando: 123/etc/init.d/slapd stop rm /var/lib/ldap/* /etc/init.d/slapd start Assim temos agora os dois servidores configurados, sendo que os dados do serv1.secure.inf.br estão sendo replicados para o servidor serv2.secure.inf.br, porém o mesmo não tem autoridade sobre os dados fazendo com que para alterarmos qualquer informação na base, teremos que fazer isso no serv1.secure.inf.br e essa atualização será replicada de imediato para o serv2.secure.inf.br. CONCLUSÃOEste trabalho tem por objetivo apresentar um protocolo extremamente importante quando falamos em centralização de aplicativos conectados em rede, o LDAP, demonstrando que este é uma ótima solução por contar com uma arquitetura distribuída, métodos nativos de segurança, contar com padrão aberto, internacionalização e suporte ao ipv6, além de diversas outras funcionalidades. Também foi demonstrado nesse trabalho o quanto flexível o protocolo LDAP pode ser, possibilitando uma gama de possibilidades para o uso do mesmo. Este foi focado na solução livre OpenLDAP , a qual, apresentou características compatíveis com ferramentas proprietárias e, em alguns casos, até mesmo os superando, isso sem a necessidade de desprendermos recursos para aquisição de licenças. Acredita-se que este servirá como instrumento de referência para estudantes e profissionais da área de tecnologia que pretendem se aprofundar nesse protocolo, que a longa data é utilizado, massivamente, em empresas de médio a grande porte de todo o mundo. REFERÊNCIAS BIBLIOGRÁFICASBARTH, D. G.; SIEWERT, V. C. Conceituação de DNS. Disponível em:http://artigocientifico.uol.com.br/uploads/artc_1148560980_24.pdf. Acesso em: jun. 2009. CARTER, G.. LDAP Administração de Sistemas. Rio de Janeiro: Alta Books, 2009. FADEL, D.. Criptografia RSA. Disponível em: < http://www.ime.unicamp.br/~ftorres/ENSINO/MONOGRAFIAS/desi_RSA.pdf>. Acesso em: nov. 2009. GOUVEIA, B.. LDAP para iniciantes. Disponível em: http://www.ldap.org.br/. Acesso em: jun. 2009. LOSANO, F.. Integração de Rede com Diretórios LDAP. Disponível em: http://www.revistadolinux.com.br/ed/025/assinantes/rede.php3. Acesso em: mar. 2009. NOVELL. Novell Documentation: Novel Audit 2.0. Disponível em: . Acesso em: abr. 2009. OPENLDAP FOUNDATION. OpenLDAP Software 2.4 Administrator’s Guide. Disponível em: http://www.openldap.org/doc/admin24/. Acesso em: mai. 2009. SANTANA, F.. Instalação do Active Directory. Disponível em: http://www.fabianosantana.com.br/windows-2000/287-ad. Acesso em: mai 2009. TRIGO, C. H. OpenLDAP: Uma abordagem integrada. São Paulo: Novatec Editora, 2007. TUTTLE, S. EHLENBERGER, A.; GORTHI, R. Understanding LDAP: Design and Implementation. Disponível em: http://www.redbooks.ibm.com/. Acesso em: abr. 2009.","link":"/2009/12/01/ldap-lightweight-directory-access-protocol/"},{"title":"Comentários destrutivos em aplicativos","text":"Olá pessoal, hoje vou tentar expor aqui algo infelizmente muito comum no dia a dia de desenvolvedores de aplicativos, em especial os independentes onde esse tipo de ação tem maior impacto, os comentários destrutivos em uma store. Este problema não se limita apenas ao contexto de aplicativos, podendo extrapolar para muitas áreas como a própria venda de produtos online, porém nesse artigo irei foca exclusivamente nesse contexto. Big Techs tem acostumado usuários a serem o produto, disponibilizando tudo sem uma cobrança direta e passando uma percepção para quem as usa ser “de graça”. Não é o intuito desse artigo entrar no mérito desta discussão, mais saiba, se não paga diretamente por uma solução, muito provavelmente é porque você e seus dados são o produto, nenhuma empresa disponibiliza uma aplicação comercial sem o intuito de ganhar dinheiro com a mesma, quem nunca pesquisou por um produto como televisão no google por exemplo, e depois em todo site que abre só vê anuncio de televisões? Essa percepção de ser tudo “grátis” está criando uma geração que espera ter tudo que precisa sem ter que disponibilizar nem mesmo alguns centavos para financiar quem vai produzir a solução, é comum encontrar sites especializados em disponibilizar aplicativos que seriam pagos nas lojas de aplicativos oficiais, muitas vezes alguns centavos, sem nenhum custo. Muitos preferem se expor e sair da segurança da loja do ecossistema e financiar o aplicativo que tanto gosta, para economizar R$ 0,99, expondo seu celular, seus dados e se colocando em risco por tão pouco. Voltando ao assunto do texto, com este cenário em mente, podemos perceber o quão difícil é para desenvolvedores independentes e mesmo empresas que não possuam o acesso e capital que as grandes empresas de tecnologia tem, criar e manter um projeto direcionado para o consumidor final ativo e principalmente rentável. Se só esses desafios não fossem suficientes, temos que administrar comentários como os abaixo, que desmerecem todo esse trabalho, desqualificam uma equipe por não atender o que esperam, ainda que não estejam dispostos a pagar para ter o que precisam. Adoraria que esses comentários fossem uma excessão, porém não são, são extremamente comuns e recheados de contradições como “Ótimo app! Se tivesse …”, “Se tivesse X seria perfeito”, etc.. Oi? Como um aplicativo que é ótimo ou quase perfeito, segundo eles, pode receber uma qualificação de apenas uma estrela? Não me entendam mal, não espero uma avaliação positiva em todos os comentários, ao contrário, muitas vezes uma qualificação negativa nos lança um feedback que pode nos ajudar a evoluir muito a solução, mas é necessário ter coerência. Uma avaliação como estas, além de prejudicar muito o impulsionamento do aplicativo dentro da loja, são um completo balde de água fria em uma equipe que está trabalhando para resolver um problema, e considerando que está usando a solução, provavelmente o seu problema. Desta forma vou propor alguns pontos que seriam incriveis se todos que forem avaliar um aplicativo usassem. 1: Sejam coerentes na avaliação, a variação existe para ser usada, não é 8 ou 80, se não gosta de tudo que está lá pese o que tem que gosta e o que não gosta e de uma avaliação justa entre esses pontos; 2: Não gostar de algum ponto ou escolha de uma funcionalidade é normal e nem sempre uma solução vai agradar a todos, mas não deixe de dar o feedback, descreva seu ponto de vista, e como a mudança poderia ser favorável. 3: Nenhuma solução nasce completa, as funcionalidades são acrescentadas muitas vezes aos poucos, se sente falta de algo, passe o feedback para a equipe, muitas vezes ter esse retorno pode fazer a equipe perceber qual funcionalidade é mais ou menos importante e priorizar de forma adequada. 4: Nunca, jamais, de forma nenhuma, vinculem um ponto, uma funcionalidade a uma avaliação positiva. É ridículo ler um comentário com algo como “Quando incluírem a funcionalidade X eu dou 5 estrelas”. Seguindo esses pontos básicos, certamente teriamos um ecosistema muito mais saudável e propício a inovação. Mas digam aí, como tem sido a experiência de vocês? Já passaram ou viram algo assim?","link":"/2021/01/16/comentarios-destrutivos-em-aplicativos/"}],"tags":[{"name":"OAuth","slug":"OAuth","link":"/tags/OAuth/"},{"name":"Autenticação Centralizada","slug":"Autenticacao-Centralizada","link":"/tags/Autenticacao-Centralizada/"},{"name":"OAuth 2","slug":"OAuth-2","link":"/tags/OAuth-2/"},{"name":"Infraestrutura","slug":"Infraestrutura","link":"/tags/Infraestrutura/"},{"name":"Ldap","slug":"Ldap","link":"/tags/Ldap/"},{"name":"Golang","slug":"Golang","link":"/tags/Golang/"},{"name":"Programação","slug":"Programacao","link":"/tags/Programacao/"},{"name":"Backend","slug":"Backend","link":"/tags/Backend/"},{"name":"Typescript","slug":"Typescript","link":"/tags/Typescript/"},{"name":"Design Patterns","slug":"Design-Patterns","link":"/tags/Design-Patterns/"},{"name":"Adapter Pattern","slug":"Adapter-Pattern","link":"/tags/Adapter-Pattern/"},{"name":"Padrões de Projeto","slug":"Padroes-de-Projeto","link":"/tags/Padroes-de-Projeto/"},{"name":"Frontend","slug":"Frontend","link":"/tags/Frontend/"},{"name":"Cloudflare","slug":"Cloudflare","link":"/tags/Cloudflare/"},{"name":"Github Pages","slug":"Github-Pages","link":"/tags/Github-Pages/"},{"name":"Observer Pattern","slug":"Observer-Pattern","link":"/tags/Observer-Pattern/"},{"name":"Slack","slug":"Slack","link":"/tags/Slack/"},{"name":"Tutoriais","slug":"Tutoriais","link":"/tags/Tutoriais/"},{"name":"Utilitario","slug":"Utilitario","link":"/tags/Utilitario/"},{"name":"PWA","slug":"PWA","link":"/tags/PWA/"},{"name":"Progressive Web Apps","slug":"Progressive-Web-Apps","link":"/tags/Progressive-Web-Apps/"},{"name":"MongoDb","slug":"MongoDb","link":"/tags/MongoDb/"},{"name":"NoSql","slug":"NoSql","link":"/tags/NoSql/"},{"name":"Banco de Dados","slug":"Banco-de-Dados","link":"/tags/Banco-de-Dados/"},{"name":"LDAP","slug":"LDAP","link":"/tags/LDAP/"},{"name":"OpenLdap","slug":"OpenLdap","link":"/tags/OpenLdap/"},{"name":"Aplicativos","slug":"Aplicativos","link":"/tags/Aplicativos/"}],"categories":[{"name":"Infraestrutura","slug":"Infraestrutura","link":"/categories/Infraestrutura/"},{"name":"Desenvolvimento","slug":"Desenvolvimento","link":"/categories/Desenvolvimento/"},{"name":"Backend","slug":"Desenvolvimento/Backend","link":"/categories/Desenvolvimento/Backend/"},{"name":"Frontend","slug":"Desenvolvimento/Frontend","link":"/categories/Desenvolvimento/Frontend/"}]}